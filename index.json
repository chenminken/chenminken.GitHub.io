[{"categories":["计算机"],"content":"Given the head of a sorted linked list, delete all nodes that have duplicate numbers, leaving only distinct numbers from the original list . Return the linked list sorted as well . class Solution { public: ListNode* deleteDuplicates(ListNode* head) { //base case if (head == nullptr) return head; ListNode dummy = ListNode(-101,head); ListNode* p = \u0026dummy; ListNode* t = p; bool ignore = false; bool one = false; while(p-\u003enext!=nullptr) { if (p-\u003enext-\u003enext != nullptr \u0026\u0026 p-\u003enext-\u003eval == p-\u003enext-\u003enext-\u003eval) { p = p-\u003enext; ignore = true; t-\u003enext = nullptr; } else if (ignore){ p = p-\u003enext; ignore = false; } else { one = true; p = p-\u003enext; t-\u003enext =p; t = p; } } return dummy.next; } }; ","date":"2021-11-04","objectID":"/posts/82.-remove-duplicates-from-sorted-list-ii/:0:0","tags":["Leet Code","C++"],"title":"82. Remove Duplicates from Sorted List II","uri":"/posts/82.-remove-duplicates-from-sorted-list-ii/"},{"categories":["计算机"],"content":"Given the head of a linked list, rotate the list to the right by k places. class Solution { public: ListNode* rotateRight(ListNode* head, int k) { // 建立一个环，维持local 和 tail两个指针。同步向前k次。 // ListNode dummy = ListNode(-1); // dummy.next = head; if (head == nullptr || k == 0) return head; ListNode* tail = head; int length = 1; while( tail-\u003enext != nullptr) { tail = tail-\u003enext; length++; } tail-\u003enext = head; ListNode* local = head; k = length - (k % length); while (k--) { tail = tail-\u003enext; local = local-\u003enext; } tail-\u003enext = nullptr; return local; } }; ","date":"2021-11-04","objectID":"/posts/61.rotate-list/:0:0","tags":["Leet Code","C++"],"title":"61.Rotate List","uri":"/posts/61.rotate-list/"},{"categories":["计算机"],"content":"You are given an array of k linked-lists lists, each linked-list is sorted in ascending order. Merge all the linked-lists into one sorted linked-list and return it. class Solution { public: struct cmp { bool operator() (ListNode* a,ListNode* b) { if(a-\u003eval == b-\u003eval) return a-\u003eval \u003e= b-\u003eval; else return a-\u003eval \u003e b-\u003eval; } }; ListNode* mergeKLists(vector\u003cListNode*\u003e\u0026 lists) { priority_queue\u003cListNode*, vector\u003cListNode*\u003e, cmp\u003e pq; ListNode dummy = ListNode(0); ListNode* p = \u0026dummy; for (auto item: lists) { if (item != nullptr) pq.push(item); } if (pq.empty()) return dummy.next; while(!pq.empty()) { p-\u003enext = pq.top(); pq.pop(); p = p-\u003enext; if (p-\u003enext != nullptr){ pq.push(p-\u003enext); } } return dummy.next; } }; ","date":"2021-11-03","objectID":"/posts/23.merge-k-sorted-lists/:0:0","tags":["Leet Code","C++"],"title":"23.Merge k Sorted Lists","uri":"/posts/23.merge-k-sorted-lists/"},{"categories":["计算机"],"content":"Merge two sorted linked lists and return it as a sorted list. The list should be made by splicing together the nodes of the first two lists. 这道题重点在 dummy 节点上。 class Solution { public: ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) { //base case if (l1==NULL) return l2; else if(l2==NULL) return l1; ListNode dummy = ListNode(-1); ListNode* p = \u0026dummy; ListNode* p1=l1; ListNode* p2=l2; while(p1!=NULL \u0026\u0026 p2!=NULL) { if(p1-\u003eval \u003e= p2-\u003eval) { p-\u003enext = p2; p = p-\u003enext; p2 = p2-\u003enext; } else { p-\u003enext = p1; p = p-\u003enext; p1 = p1-\u003enext; } } if(p1 != NULL) { p-\u003enext = p1; } if(p2 != NULL) { p-\u003enext = p2; } return dummy.next; } }; ","date":"2021-11-03","objectID":"/posts/21.-merge-two-sorted-lists/:0:0","tags":["Leet Code","C++"],"title":"21. Merge Two Sorted Lists","uri":"/posts/21.-merge-two-sorted-lists/"},{"categories":["计算机"],"content":"Given an integer array nums, return the length of the longest strictly increasing subsequence. A subsequence is a sequence that can be derived from an array by deleting some or no elements without changing the order of the remaining elements. For example, [3,6,2,7] is a subsequence of the array [0,3,1,6,2,2,7]. //时间复杂度 O(N^2) class Solution { public: int lengthOfLIS(vector\u003cint\u003e\u0026 nums) { vector\u003cint\u003e dp(nums.size(),1); // 组建dp数组 for (int i=1; i\u003cnums.size();i++) { for (int j=0; j\u003ci; j++) { if (nums[j] \u003c nums[i] ) dp[i] = max(dp[i], dp[j]+1); } } int res = 0; for (int i=0; i\u003cnums.size();i++) { res = max(res, dp[i]); } return res; } }; ","date":"2021-11-02","objectID":"/posts/300.longest-increasing-subsequence/:0:0","tags":["Leet Code","C++"],"title":"300.Longest Increasing Subsequence","uri":"/posts/300.longest-increasing-subsequence/"},{"categories":["计算机"],"content":"Given an integer array nums, find the contiguous subarray (containing at least one number) which has the largest sum and return its sum . A subarray is a contiguous part of an array. class Solution { public: int maxSubArray(vector\u003cint\u003e\u0026 nums) { vector\u003cint\u003e dp(nums.size(), 0); dp[0] = nums[0]; for (int i=1; i\u003cdp.size(); i++) { dp[i] = max(nums[i], dp[i-1]+ nums[i]); } int res = INT_MIN; for (int i=0; i\u003cdp.size(); i++) { res = max(res, dp[i]); // printf(\"%d \", dp[i]); } return res; } }; ","date":"2021-11-02","objectID":"/posts/53.-maximum-subarray/:0:0","tags":["Leet Code","C++"],"title":"53. Maximum Subarray","uri":"/posts/53.-maximum-subarray/"},{"categories":["计算机"],"content":"Coin Change You are given an integer array coins representing coins of different denominations and an integer amount representing a total amount of money. Return the fewest number of coins that you need to make up that amount. If that amount of money cannot be made up by any combination of the coins, return -1. You may assume that you have an infinite number of each kind of coin. class Solution { public: int coinChange(vector\u003cint\u003e\u0026 coins, int amount) { vector\u003cint\u003e dp(amount+1,amount+1); dp[0] = 0; for (int i=1; i\u003camount+1; i++) { for (auto coin: coins) { if (i-coin \u003c 0 || dp[i-coin] == -1) continue; dp[i] = min(dp[i], dp[i-coin]+1); } } return dp.back()== amount+1 ? -1 : dp.back(); } }; ","date":"2021-11-01","objectID":"/posts/322.coin-change/:0:0","tags":["Leet Code","C++"],"title":"322.Coin Change","uri":"/posts/322.coin-change/"},{"categories":["计算机"],"content":"Given a string containing just the characters ‘(’ and ‘)’, find the length of the longest valid (well-formed) parentheses substring. class Solution { public: int longestValidParentheses(string s) { // using stack to process stack\u003cint\u003e v; // 找到所有配对的括号 for (int i=0; i\u003cs.length();i++) { if (s[i] == '(') { v.push(i); } else if (v.size()) { s[v.top()] = s[i] = '*'; v.pop(); } } int current = 0; int res = 0; for (int i=0; i\u003cs.length(); i++) { if (s[i] == '*') { current++; res = max(res, current); } else { res = max(res, current); current = 0; } } return res; } }; ","date":"2021-11-01","objectID":"/posts/32.longest-valid-parentheses/:0:0","tags":["Leet Code","C++"],"title":"32.Longest Valid Parentheses","uri":"/posts/32.longest-valid-parentheses/"},{"categories":["个人"],"content":"算上在火车上听的内容，我已经把《富兰克林自传》看完了。英国议会的那一个章节(第四封信)，我只听了没有第二遍看。对于政治的东西目前没有想太了解。 我觉得本杰明富兰克林是一个伟大的人。他的伟大之处不仅是在于他作为美国的开国元勋之一，也不仅在于他所发现的电学的现象。更在于它所写的这本自传，带给了很多人启迪。其中肯定有叔本华，因为我是从叔本华的《人生的智慧》中知道了这本书。如今这本书也给我带来的启迪。老实说，我读这本书的时机非常恰巧。是我在跟一个女生表白被拒之后，心有点失望的时候读的。我问了我身上存在的哪些问题？话太多且不会说话、严肃拘谨。 本杰明富兰克林有阅读的习惯。年少的时候曾经制定一个伟大的计划。他还是一个信徒。他的十三个计划基本上可以为我自己所用。他对很多事情的看法很透彻。 他对于写自传的看法是:『不过，既然再活一遍没有指望。只好退而求其次。最像再活一次的事情似乎就是对这一生的一种反思。』 对于如何提高自己的写作能力，他提出一个我觉得很可行，但又是很繁复的方法。就是找到一个你认为好的写作的模板，看一遍把大意写下来，与原文加以对比，发现了一些错误，予以改正。我常常发现自己会语言词汇贫乏，而且词不达意。富兰克林在开始的时候也是这样子的。？而我要再考虑一下怎么去应用这个方法，首先要找到一个合适的范文。 他为自己犯过的错误以这样的一种态度描述:『我的行为也许该受责难。但我随他去，不做进一步的辩解。因为我眼下的目的是陈述事实，而不是为它们辩护。』 这部自传中我最喜欢的就是他论习惯的部分。 富兰克林将自己制定计划的过程和困难列了出来。“麻脸斧头＂的比喻十分生动。我可不想让自己认为＂我想我最喜欢的就是麻脸斧头＂。树立良风，破除陋习是十分困难的，我的感觉是自己的失败大多是对陋习根深蒂固的不了解，或者是轻率。有过两三年，在年初的时候制定了一系列的计划：要读书，要健身。但是马上现实打倒了我。只要一个中断就足以摧毁整个计划。换言之，过于乐观，二元结果的计划注定是要失败的。依我看来，一个还比较可行的计划应该避免：每天，只要有一天中断，之前所有的努力都白费。？ 我计划按照富兰克林的＂美德养成计划来规范自己的行为。用13周的时间去实践美德，每周专注一项美德，记录其他美德在一天之内没遵守的情况。一年刚好4个周期。 我从自传中学到一些与人相处的思路，比如：『跟自己必须朝夕相处的人交恶是愚蠢透顶的』。还有『我逐渐相信人际关系中的真实、诚信、正直对于人生的幸福至关重要』。 对于交谈，我过往的习惯是辩论和纠错式的，很多的交谈不是打仗， 不需要分出胜负，更重要的是和谐。『由于交谈的主要目的是提供信息或者获取信息，使人心悦或使人信服，所以我希望善意明达之人不要以武断自负的方式说话，而使行善的力量减弱。』 对于酒和烟草，我很庆幸自己没有受到两者的诱惑。看看富兰克林是怎么形容他在伦敦的印刷所喝酒的同仁们的吧：『每个星期六晚上，为了喝那种迷魂汤，要从一周的工资中拿出四五个先令；这笔开销我可免了。就这样，那些可怜鬼总是把自己搞得紧巴巴的』。我在回到家乡后看到家乡的一些亲人每两三天抽一包烟，且不论烟酒对身体的影响，假设每包烟20元，一年则需要花费大约3640元在买烟上。 最后我总结了一下富兰克林在自传中称赞的一些品质：脚踏实地、通情达理、勤奋、节制、古道热肠、乐善好施、敬业、身体健壮。 我目前没有信仰上帝的倾向，但是对佛教和上帝有了更多的兴趣。 至于我所悲伤的事情，流感提供给我一个能够不受打扰的闲暇时间，而表白失败提供了一次让我重新审视自己的机会。像叔本华说的那样如黄金般珍贵的闲暇时间，我怎么能浪费呢。预计再读一本《Educated》，搜索一些毕业设计的论文。然后就等着不知何时的开学吧。 由于我们的感觉大都固守于一时，所以容易忘记这一时过后，还有更多的时机接踵而来，因此，人应当合理安排自己的行为，以适应终身的需要。 我的爱差不多是这样。即使不愿意，也要往前看，因为事实已经发生了，回不去，不管无奈与否，接下来发生的事情与时机不以你的意志为转移。 第一次初稿 January 25, 2020 8:38 AM 段落之间的连接很弱。基本是信息的流动而已。 ","date":"2021-10-29","objectID":"/posts/%E5%AF%8C%E5%85%B0%E5%85%8B%E6%9E%97%E8%87%AA%E4%BC%A0/:0:0","tags":["读书笔记"],"title":"富兰克林自传","uri":"/posts/%E5%AF%8C%E5%85%B0%E5%85%8B%E6%9E%97%E8%87%AA%E4%BC%A0/"},{"categories":["计算机"],"content":"课题组要部署一个云服务，之前用的是我个人申请的学生版服务器，价格优惠。快到期需要续费，但是优惠版的服务器不能够继续以优惠价格续费，正常的价格是一千多每年。所以我决定新申请一个优惠版服务器，然后迁移Postgres数据库和部署的web server。 基本步骤是购买新服务器（Ubuntu18.04版本），密码重设，为了方便登录也可以设置ssh免密码登录。 ","date":"2021-10-29","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:0:0","tags":["数据库"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"安装配置Postgres 我觉得Postgres比MySQL好的一点在于其开源。且能实现数据库的基本功能。 ","date":"2021-10-29","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:1:0","tags":["数据库"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"服务器安装Postgres sudo apt-get install postgresql postgresql-client 可以在本机安装一个postgres-client，免得在两个服务器之间来回登录。 ","date":"2021-10-29","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:1:1","tags":["数据库"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"配置postgres数据库账号和远程连接 登录新服务器，设置linux中的postgres用户密码 sudo passwd postgres或者sudo -i -u postgres，免密码登录。 设置postgres 中postgres用户密码(以postgres用户登录) psql进入数据库clinet软件 postgres \\password设置数据库管理员postgres的密码 ","date":"2021-10-29","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:1:2","tags":["数据库"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"远程连接设置 修改Postgres远程连接允许 sudo vim /etc/postgres/10/main/postgres.conf， 修改listen_addresses那一行为listen_addresses = '*'（有的公司要求不允许数据库开放外网访问，请谨慎该选项）。 修改远程登录选项 vim /etc/postgres/10/main/pg_dba.conf 添加新行 host all all 0.0.0.0/0 md5 (不要使用trust，除非你想任何人能够访问你的数据库内容) 重启服务以应用刚刚的修改 sudo service postgresql restart 参考 ","date":"2021-10-29","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:1:3","tags":["数据库"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"数据库迁移 Postgres 提供导出数据库数据和结构的程序。有两种方法，一种是在本机安装psql程序，新旧服务器都进行上面的远程连接设置，然后本机连接源服务器数据库dump备份文件，然后本机连接目标服务器数据库导入数据；另外一种是登录源服务器dump备份文件，再导出到目标服务器，在目标服务器执行导入操作。我使用的是比较麻烦的第二种。 ","date":"2021-10-29","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:2:0","tags":["数据库"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"备份数据库 pg_dump -h (ip or localhost) -U postgres databasename \u003e databasename.bak 我是在服务器本地进行的操作，所以可以使用localhost。 ","date":"2021-10-29","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:2:1","tags":["数据库"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"恢复数据库 恢复数据库指令不会创建新的数据库，所以需要先行在新的数据库中创建数据库 create database databasename; 然后执行psql -h localhost -U postgres -d databasename \u003c databasename.bak恢复数据库。 参考 原文网站：新服务器迁移postgres数据库 ","date":"2021-10-29","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:2:2","tags":["数据库"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"We run a preorder depth-first search (DFS) on the root of a binary tree. At each node in this traversal, we output D dashes (where D is the depth of this node), then we output the value of this node. If the depth of a node is D, the depth of its immediate child is D + 1. The depth of the root node is 0. If a node has only one child, that child is guaranteed to be the left child. Given the output traversal of this traversal, recover the tree and return its root. class Solution { public: string tra; int pos=0; TreeNode* recoverFromPreorder(string traversal) { this-\u003etra = traversal; TreeNode* root = NULL; root = solve(root, 0); return root; } TreeNode* solve(TreeNode* root, int depth) { int strDepth = 0; for (int i=this-\u003epos; i \u003c this-\u003etra.size(); i++) { if (this-\u003etra[i] == '-') { strDepth++; } else { break; } } if (strDepth !=depth) { return NULL; } this-\u003epos+=strDepth; int numLen = 0; for (int i= this-\u003epos; i \u003cthis-\u003etra.size(); i++ ) { if (this-\u003etra[i] != '-') { numLen++; } else { break; } } int val = stoi(this-\u003etra.substr(this-\u003epos, numLen)); this-\u003epos+=numLen; root = new TreeNode(val); root-\u003eleft = solve(root-\u003eleft, depth+1); root-\u003eright = solve(root-\u003eright,depth+1); return root; } }; ","date":"2021-10-29","objectID":"/posts/1028.-recover-a-tree-from-preorder-traversal/:0:0","tags":["Leet Code","C++"],"title":"1028. Recover a Tree From Preorder Traversal","uri":"/posts/1028.-recover-a-tree-from-preorder-traversal/"},{"categories":["计算机"],"content":"A path in a binary tree is a sequence of nodes where each pair of adjacent nodes in the sequence has an edge connecting them. A node can only appear in the sequence at most once. Note that the path does not need to pass through the root. The path sum of a path is the sum of the node’s values in the path. Given the root of a binary tree, return the maximum path sum of any path. class Solution { public: int ans = INT_MIN; int maxPathSum(TreeNode* root) { sideMax(root); return ans; } int sideMax(TreeNode* root) { if (root == nullptr) return 0; int left = max(0, sideMax(root-\u003eleft)); int right = max(0, sideMax(root-\u003eright)); // 后序遍历代码位置 ans = max(ans, left + right + root-\u003eval); // 避免分叉 return max(left, right) + root-\u003eval; } }; ","date":"2021-10-29","objectID":"/posts/124.-binary-tree-maximum-path-sum/:0:0","tags":["Leet Code","C++"],"title":"124. Binary Tree Maximum Path Sum","uri":"/posts/124.-binary-tree-maximum-path-sum/"},{"categories":["计算机"],"content":"Given the root of a binary tree and an integer targetSum, return all root-to-leaf paths where the sum of the node values in the path equals targetSum. Each path should be returned as a list of the node values, not node reference. A root-to-leaf path is a path starting from the root and ending at any leaf node. A leaf is a node with no children. class Solution { public: vector\u003cvector\u003cint\u003e\u003e result; vector\u003cvector\u003cint\u003e\u003e pathSum(TreeNode* root, int targetSum) { vector\u003cint\u003e currentPath; pathSum(root, targetSum, currentPath, 0); return result; } void pathSum(TreeNode* root, int targetSum, vector\u003cint\u003e currentPath, int currentSum) { if (root == NULL) { return; } currentPath.push_back(root-\u003eval); currentSum += root-\u003eval; if(root-\u003eleft == NULL \u0026\u0026 root-\u003eright == NULL) { if (currentSum == targetSum) { result.push_back(currentPath); } } pathSum(root-\u003eleft, targetSum, currentPath, currentSum); pathSum(root-\u003eright, targetSum, currentPath, currentSum); } }; ","date":"2021-10-29","objectID":"/posts/113.-path-sum-ii/:0:0","tags":["Leet Code","C++"],"title":"113. Path Sum II","uri":"/posts/113.-path-sum-ii/"},{"categories":["计算机"],"content":"Given the root of a binary tree and an integer targetSum, return true if the tree has a root-to-leaf path such that adding up all the values along the path equals targetSum. A leaf is a node with no children. class Solution { public: bool hasPathSum(TreeNode* root, int targetSum, int currentSum=0) { if (root == NULL) { return false; } currentSum += root-\u003eval; if (root-\u003eleft == NULL \u0026\u0026 root-\u003eright == NULL) { if (currentSum != targetSum) { return false; } else return true; } bool left = hasPathSum(root-\u003eleft, targetSum,currentSum); bool right = hasPathSum(root-\u003eright, targetSum,currentSum); return left || right; } }; ","date":"2021-10-29","objectID":"/posts/112.-path-sum/:0:0","tags":["Leet Code","C++"],"title":"112. Path Sum","uri":"/posts/112.-path-sum/"},{"categories":["计算机"],"content":" /** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */ class Solution { public: TreeNode* buildTree(vector\u003cint\u003e\u0026 preorder, vector\u003cint\u003e\u0026 inorder) { // 转换inorder为map unordered_map\u003cint, int\u003e inMap; for (int i=0; i\u003cinorder.size(); i++) { inMap[inorder[i]] = i; } // 调用 buildTree return buildTree(preorder, inorder, 0, preorder.size()-1, 0, inorder.size()-1, inMap); } TreeNode* buildTree(vector\u003cint\u003e\u0026 preorder, vector\u003cint\u003e\u0026 inorder, int preStart, int preEnd, int inStart, int inEnd, unordered_map\u003cint, int\u003e\u0026 inMap) { if (preStart \u003e preEnd || inStart \u003e inEnd) return NULL; // 封装root在pre和in中的位置。 int preRootVal = preorder[preStart]; int inRoot = inMap[preRootVal]; // for (int i=0; i\u003cinorder.size(); i++) { // if (preRootVal == inorder[i]){ // inRoot = i; // break; // } // } // 寻找left 长度 int leftLen = inRoot - inStart; int rightLen = inEnd - inRoot; TreeNode* root = new TreeNode(preRootVal); //分治 root-\u003eleft = buildTree(preorder,inorder, preStart+1,preStart+leftLen, inStart, inRoot-1, inMap); root-\u003eright = buildTree(preorder,inorder, preStart+leftLen+1, preEnd, inRoot+1,inEnd, inMap); return root; } }; ","date":"2021-10-29","objectID":"/posts/105.-construct-binary-tree-from-preorder-and-inorder-traversal/:0:0","tags":["Leet Code","C++"],"title":"105. Construct Binary Tree from Preorder and Inorder Traversal","uri":"/posts/105.-construct-binary-tree-from-preorder-and-inorder-traversal/"},{"categories":["计算机"],"content":"You are given the root of a binary search tree (BST), where the values of exactly two nodes of the tree were swapped by mistake. Recover the tree without changing its structure. class Solution { public: TreeNode* prev, * first, * second; void recoverTree(TreeNode* root) { inorder(root); swap(first-\u003eval, second-\u003eval); } void inorder(TreeNode* root) { if (root == NULL) { return; } inorder(root-\u003eleft); //code here if (prev != NULL \u0026\u0026 prev-\u003eval \u003e root-\u003eval) { if (first == NULL) { first = prev; } second = root; } prev = root; inorder(root-\u003eright); } };x ","date":"2021-10-29","objectID":"/posts/99-recover-binary-search-tree/:0:0","tags":["Leet Code","C++"],"title":"99 Recover Binary Search Tree","uri":"/posts/99-recover-binary-search-tree/"},{"categories":["计算机"],"content":"Given the root of a binary tree, return the inorder traversal of its nodes' values. /** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */ class Solution { public: vector\u003cint\u003e inorderTraversal(TreeNode* root) { vector\u003cint\u003e ret; if (root == nullptr) { return ret; } ret.push_back(root-\u003eval); vector\u003cint\u003e left = inorderTraversal(root-\u003eleft); // inorder left.insert(left.end(),ret.begin(),ret.end()); vector\u003cint\u003e right = inorderTraversal(root-\u003eright); left.insert(left.end(),right.begin(),right.end()); return left; } }; ","date":"2021-10-29","objectID":"/posts/94binary-tree-inorder-traversal/:0:0","tags":["Leet Code","C++"],"title":"94Binary Tree Inorder Traversal","uri":"/posts/94binary-tree-inorder-traversal/"},{"categories":null,"content":"这篇文章是“讨伐”印象笔记的。并且给出快捷迁移印象笔记中的数据的方式 ","date":"2021-10-28","objectID":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/:0:0","tags":null,"title":"不会吧2021年还在用印象笔记?（附快捷迁移指南）","uri":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"印象笔记对我的影响 我是在2014年高中的时候开始使用印象笔记。当时是在一些软件评测网站还有知乎上看到有人分享自己使用印象笔记的心得。那句“Elephants never forget\"还有”第二大脑“的比喻深得我心。所以我开始使用印象笔记。前两年仅仅是免费的每月60MB的方案就已经够我写日记和规划高考复习计划。后面则开始购买高级会员。因为其既符合能够本地保存，又能多设备多平台同步，十分方便，就一直作为主力的记录软件。 印象笔记最好用的功能有三个：剪藏、提醒、标签嵌套 剪藏 从浏览器，网页，APP中把网址通过\"分享\"传给印象笔记。离线下载 提醒 轻量级GTD的组件 标签嵌套 在了解到大纲之前，标签是我组织知识树结构的一种方式。而标签的嵌套能够让这一个知识树成为可能。 直到2020年的5月，我都在使用印象笔记记录日记、摘录网上的文章、记录学业项目上的事情。并且一共积攒下9000多条的笔记。可是在那之后，渐渐的，印象笔记好像出了点问题，而我的知识管理的需求也发生了改变。 ","date":"2021-10-28","objectID":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/:1:0","tags":null,"title":"不会吧2021年还在用印象笔记?（附快捷迁移指南）","uri":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"为何不再使用印象笔记 ","date":"2021-10-28","objectID":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/:2:0","tags":null,"title":"不会吧2021年还在用印象笔记?（附快捷迁移指南）","uri":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"吃相难看，破坏基本面 不再使用印象笔记的原因有三个。其中最重要的就是印象笔记吃相难看，中国团队独立出来后，商业化逐渐让印象笔记变得面目全非，失去灵魂。一个笔记软件最重要的是保证增删改查的基本功能。一开屏，即使是专业版会员都要面对着弹窗广告、侧边栏广告、顶栏广告。鲜艳的黄底十分分散注意力。 ","date":"2021-10-28","objectID":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/:2:1","tags":null,"title":"不会吧2021年还在用印象笔记?（附快捷迁移指南）","uri":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"新增功能不稳定 印象笔记在本地化之后新增了超级笔记，素材库，空间，知识图谱等功能。使得操作逻辑变得混乱的同时还经常出现bug。超级笔记是基于web技术渲染的，经常出现无法删除某一行的bug。还有一选中就把整个编辑器给选中的神奇现象。 ","date":"2021-10-28","objectID":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/:2:2","tags":null,"title":"不会吧2021年还在用印象笔记?（附快捷迁移指南）","uri":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"剪藏是否是一个好习惯 剪藏让收集新信息变得容易了。同时也让很多信息只是被收藏起来了。印象笔记的笔记是按照列表自动排序的，很多以前剪藏的文章没有机会被第二次审视。在决定好好整理一下自己的知识库之后，我利用了半年时间删除掉了7000多条以后用不到的或者价值不高的剪藏和课堂笔记。而成体系的东西用workflowy进行整理梳理。 ","date":"2021-10-28","objectID":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/:2:3","tags":null,"title":"不会吧2021年还在用印象笔记?（附快捷迁移指南）","uri":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"如何迁移自己的第二大脑，迁移去哪？ 在这几年的实践中，我越来越深刻的感受到“第二大脑”是对自己知识体系，理解能力的一种存储。和用什么具体的工具来存储关系不算很大。只要这些工具具备内链（或者双向链接），markdown语法，多端同步还有方便导出的渠道就足够了。 而符合这些特征的软件数不胜数。比如notion，我来，思源笔记，roam research， 为知笔记和国际版的Evernote。其中和印象笔记最接近的是父辈Evernote，现在的Evernote也已经拥抱了前端技术，整体体验接近云笔记。其缺点非常明显，每年接近500元的订阅费用。 其中“我来”和“为知笔记”都提供直接导入印象笔记的功能。 以下简单介绍两款国产产品我来和为知笔记。 ","date":"2021-10-28","objectID":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/:3:0","tags":null,"title":"不会吧2021年还在用印象笔记?（附快捷迁移指南）","uri":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"我来 一款类似notion的云笔记。目前年收费120元（教育优惠99元左右）。设计简洁，bug较少。体验还是比较统一的。 我来支持多种导入方式，其中印象笔记的导入是导入enex文件。这类的云笔记缺点是云端处理。所以上传的文件不能太大。一次也只能导入一两百条。 在导入过程中会丢失标签信息。 如果想注册可以通过我的邀请码注册，给我一些福利。https://www.wolai.com/signup?invitation=CJD4ZUP ","date":"2021-10-28","objectID":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/:3:1","tags":null,"title":"不会吧2021年还在用印象笔记?（附快捷迁移指南）","uri":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"为知笔记 为知笔记是一个很老牌的和印象笔记同期的笔记软件，它是本地优先的多目录层级笔记软件。年收费60元。其设计思路和印象笔记大体是一致的。主要也是一种富文本编辑器。最近为知笔记频繁更新WizNote X，试图简化UI，使用markdown，让用户更容易使用。可是新的产品问题也是明显的，笔记编辑容易出现bug。我使用的是windows端的旧版的wiznote 导入。导入的前提是需要安装好印象笔记然后登陆进去。为知笔记会自动搜寻印象笔记的数据库文件从而自动导入。标签不会丢失，但是标签的嵌套关系会丢失。 ","date":"2021-10-28","objectID":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/:3:2","tags":null,"title":"不会吧2021年还在用印象笔记?（附快捷迁移指南）","uri":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"总结 过去十多年，印象笔记是笔记软件的C位。但是在国内团队独立之后，曾经低价好用的笔记软件已经离我们而去了。而随着各种新的理念如“双链笔记”，“块”，“One for ALL”，“workspace”的兴起。各种笔记软件如同雨后春笋一般兴起，让人眼花缭乱。笔记软件的本质是一个外挂存储和一个进行思考的空间。笔记软件的目的是为了能够促进思考，在该用的时候快速查看。笔记存而不用才是大问题。频繁的体验测试新的软件则会产生副作用。不如找一个性价比、体验都不错的软件，比如“我来”，“为知”或者“notion”。如果还是希望使用印象笔记，那么推荐国际服Evernote。 ","date":"2021-10-28","objectID":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/:4:0","tags":null,"title":"不会吧2021年还在用印象笔记?（附快捷迁移指南）","uri":"/posts/%E4%B8%8D%E4%BC%9A%E5%90%A72021%E5%B9%B4%E8%BF%98%E5%9C%A8%E7%94%A8%E5%8D%B0%E8%B1%A1%E7%AC%94%E8%AE%B0%E9%99%84%E5%BF%AB%E6%8D%B7%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/"},{"categories":["计算机"],"content":"安装CVAT，使用docker安装其实很明确，但是国内的网络环境很复杂，容易报错。 ","date":"2020-12-09","objectID":"/posts/cvat%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/:0:0","tags":["Linux"],"title":"cvat安装指南","uri":"/posts/cvat%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/"},{"categories":["计算机"],"content":"关键词：数组去重 题目描述： Given a sorted array nums, remove the duplicates in-place such that each element appear only once and return the new length. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. 这道题需要更改原始输入的数组并且返回去重后的数组长度。 分为两部分来思考： 去重数组长度计算 注意到这里的输入数组是排好序的数组。所以可以用指针从头开始比较。并设置去重后的数组长度为count=0. 用count也可以作为数组的指针，来表示数组在count这个位置的数值。 肯定要遍历整个数组，用一个for循环和i指针来做。 在这里我一开始的思路是判断count指针和i指针大小，如果count指针所指的数小则将count++。最后count就是要求的数组长度。 更改原始输入数组 题目要求必须在原始数组上进行更改而不能新建一个数组。有一个隐含前提，去重数组的长度一定小于等于原始数组。那么，我们可以直接将大于当前指针的数放入前一个已经去重的数之后。 所以我们需要一个指针来保存去重列表的末尾部分,恰好这个指针就是count，当i指针遍历整个数组遇到一个新的数（只需要比count的大）时，可以将这个数放入count之后的格子里，直到i遍历到达了整个原始数组的尾部。 需要考虑边界条件。当输入数组nums的长度为0和1时，这个算法是否能够给出0,1的返回值？不能。count=0的初始设置在nums.length=1时还是等于0.因为count==i==0，并不会进入自增的过程。可以考虑返回count+1，然后在算法顶端加一个判断条件。数组的长度是否为0，如果是0，直接返回0就好了。 Java版本的代码如下： public int removeDuplicates(int[] nums) { if(nums.length == 0){ return 0; } int count = 0; for(int i=1; i\u003c nums.length; i++) { if(nums[count] \u003c nums[i]){ nums[count+1] = nums[i]; count++; } } return count+1; } ","date":"2020-11-23","objectID":"/posts/leetcode26/:0:0","tags":["Leet Code","C++"],"title":"LeetCode26","uri":"/posts/leetcode26/"},{"categories":["计算机"],"content":"这篇文章是学习Kaldi的第二篇。对应SUSTech CS310课程的Lab6和Lab7。 第一篇里探索了如何对toy language（仅包含两个单音素单词）进行语言模型的建模。至于训练和解码的部分，时间条件和理解能力暂时不允许去整理。 本篇文章的主要目标是理解复杂的中文多音素语言模型和使用AiShell语料集来真实的训练出一个可用的中文语音识别模型。完整的AiShell例子包含GMM-HMM和神经网络。Lab6先展示了GMM-HMM后的结果。Lab7则补充了神经网络。 ","date":"2020-11-23","objectID":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/:0:0","tags":["NLP","ASR"],"title":"学习Kaldi：中文Aishell项目（上）","uri":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/"},{"categories":["计算机"],"content":"AiShell描述和下载 AiShell 是 ？？公司开源的中文普通话语料集。400个来自不同方言区的人参与录制， 录制的条件是在室内使用高保真的麦克风，音频降采样到16000Hz。 //中文文字脚本95%的准确度 //170小时的语料。划分为85%的训练集，10%的开发集（作用？），5%的测试集。在上课的时候我被录制语料的成本吓到了，2000小时的语料大约需要100万人民币的费用。 AiShell语料集可以免费由于学术目的。 语料集下载 Kaldi中包含Aishell的示例脚本。在kaldi/egs/aishell/s5中。下文所有的文件都在该目录之下。 下载语料集的脚本包含在run.sh中。 先安装好语言模型的工具才能运行run.sh run ./install_kaldi_lm.sh \u0026\u0026 source ../env.sh 上一篇文章没有说每一个项目下的s5文件夹中有什么，在网上找到了别人写的一个总结：kaldi 源码分析(三) - run.pl 分析 cmd.sh # 并行执行命令，通常分 run.pl, queue.pl 两种 config # 参数定制化配置文件， mfcc, decode, cmvn 等配置文件 local # 工程定制化内容 path.sh # 环境变量相关脚本 run.sh # 整体流程控制脚本，主入口脚本 steps # 存放单一步骤执行的脚本 utils # 存放解析文件，预处理等相 关工具的脚本 最重要的入口脚本是run.sh。包含所有脚本。如果要在本地运行，需要修改这个脚本。把其中的queue.pl改成run.pl。 export train_cmd=\"run.pl\" export decode_cmd=run.pl export mkgraph_cmd=\"run.pl\" 先做Lab6，注释掉神经网络训练部分。为了对比加不加神经网络对最后的识别准确率有多大的影响。 # nnet3 #local/nnet3/run_tdnn.sh # chain #local/chain/run_tdnn.sh ","date":"2020-11-23","objectID":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/:1:0","tags":["NLP","ASR"],"title":"学习Kaldi：中文Aishell项目（上）","uri":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/"},{"categories":["计算机"],"content":"运行run.sh脚本，一步到位 在上一篇文章中，主要讲了kaldi的工作流程，复杂一点的项目除了要考虑多音素的对齐以外？基本流程是差不多的。先运行整体流程脚本run.sh看一下效果。然后再具体深入进脚本中看有哪些关键步骤。 你是否遇到过连接远程服务器跑训练，然后网络掉线杀掉了正在跑的进程？我遇到过，后来主要使用nohup来避免这个问题。课件里推荐使用screen来避免远程登陆进程被杀掉后，训练进程也停止的问题。screen的原理不是本篇文章关心的重点。 加上screen后运行run.sh： screen -S run run ./run.sh 就能看到脚本在一个新的页面输出内容了。 如果要结束进程 ctrl a + d//我其实不喜欢这个命令，因为很经常使用ctrl+a来编辑命令，两个快捷键冲突。 ","date":"2020-11-23","objectID":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/:2:0","tags":["NLP","ASR"],"title":"学习Kaldi：中文Aishell项目（上）","uri":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/"},{"categories":["计算机"],"content":"查看结果 中文语音识别的准确度通常使用CER（Char Error Rate）来表示。因为中文中字是最小语义单位，而英文中词是基本语义单位。 和上一篇文章差不多的命令。脚本的运行结果保存在了exp目录下。 for x in exp/*/decode_test; do [ -d $x ] \u0026\u0026 grep WER $x/cer_* | utils/best_wer.sh; done 2\u003e/dev/null 训练出来的结果如下： 可以cat RESULTS，和官方跑出来的结果做一下对比。 需要注意的是，和上篇文章的实验不一样的是，输出的结果是多行的，因为执行了多次的实验，上面的脚本输出的是每次实验最好的结果。 我自己跑出来的最好结果是tri5a的cer_14_0.5而RESULTS中的GMM-HMM模型中最好的结果是tri5a的cer_13_0.5。两者CER都是12.12。每次实验本身都有一定的随机性。结果有一些误差是没问题的。为了确认模型有被正确的训练，查看自己结果的tri5a/decode_test/cer_13_0.5的CER是12.18，恰好不是最优解而已。这里的13和14是lmwt（语言模型权重）。具体的可以看上一篇文章。 ","date":"2020-11-23","objectID":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/:3:0","tags":["NLP","ASR"],"title":"学习Kaldi：中文Aishell项目（上）","uri":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/"},{"categories":["计算机"],"content":"细节 使用命令cat run.sh | grep \"#\"将run.sh脚本中的环节注释提取打印出来。其中倒数2，4行是我们在一开始注释掉的。可以看到基本可以分为准备、训练和获取结果三个部分。 ","date":"2020-11-23","objectID":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/:4:0","tags":["NLP","ASR"],"title":"学习Kaldi：中文Aishell项目（上）","uri":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/"},{"categories":["计算机"],"content":"准备 下载语料集 需要注意的是aishell语料集有大概20GB的大小。意味着需要很长的时间才能下载下来。我是直接用服务器里提前下好的语料集。 local/download_and_untar.sh $data $data_url data_aishell || exit 1; 这里的 a || b是一个逻辑符号，代表着如果a执行失败则执行b。这里要放一个小插曲。去年面试阿里云的实习项目时，面试官开头就问了如何知道上一条linux命令是否成功执行。我当时不知道，现在要知道了。就是看变量$?的值，如果为0代表成功执行。这里的exit 1终止当前进程并且将$?设置为1。表示不成功执行。 $data 是aishell在本机的位置，既可以新建一个空目录来下载，也可以指定到已经下好的路径，aishell 分为resource_aishell和data_aishell两部分来下载，脚本会通过检查每一个部分下是否有.complete文件来判断当前部分是否下载完全。如果没有才会到指定网址下载。 2. Lexicon Preparation local/aishell_prepare_dict.sh $data/resource_aishell || exit 1; 这个脚本的功能主要是将resource_aishell下的lexicon.txt复制到data/local/dict中。并且提取出nonsilence_phones.txt、optional_silence.txt 、silence_phones.txt和extra_questions.txt。用到了很多awk和perl的脚本。没看懂。（要是看懂了，第一次assignment就不会搞砸了） 那就要求自己看懂把。 每行代表一组相同的base phone,包含各种不同的重音或者声调。 Data preparation local/aishell_data_prep.sh $data/data_aishell/wav $data/data_aishell/transcript || exit 1; $data/data_aishell/wav目录下放着的是音频文件。其中有两级目录speaker/filename.wav。 $data/data_aishell/transcript目录下放着的是aishell_transcript_v0.8.txt文字翻录。 这个shell脚本的功能是将$data/data_aishell/wav下的 train,test,dev分别建立索引。并且建立Kaldi能够理解的语料格式。具体有些什么可以参考上一篇文章和下面这一段脚本。 # Transcriptions preparation for dir in $train_dir $dev_dir $test_dir; do echo Preparing $dir transcriptions # 将当前集合目录下的wav的文件名提取出来作为utt_id sed -e 's/\\.wav//' $dir/wav.flist | awk -F '/' '{print $NF}' \u003e $dir/utt.list # 根据目录结构建立utt2spk的关系 sed -e 's/\\.wav//' $dir/wav.flist | awk -F '/' '{i=NF-1;printf(\"%s %s\\n\",$NF,$i)}' \u003e $dir/utt2spk_all # 按列合并utt.list和wav.flist，达到对音频文件的映射。 paste -d' ' $dir/utt.list $dir/wav.flist \u003e $dir/wav.scp_all utils/filter_scp.pl -f 1 $dir/utt.list $aishell_text \u003e $dir/transcripts.txt awk '{print $1}' $dir/transcripts.txt \u003e $dir/utt.list utils/filter_scp.pl -f 1 $dir/utt.list $dir/utt2spk_all | sort -u \u003e $dir/utt2spk utils/filter_scp.pl -f 1 $dir/utt.list $dir/wav.scp_all | sort -u \u003e $dir/wav.scp sort -u $dir/transcripts.txt \u003e $dir/text utils/utt2spk_to_spk2utt.pl $dir/utt2spk \u003e $dir/spk2utt done 4. Phone sets, questions, L compilation utils/prepare_lang.sh --position-dependent-phones false data/local/dict \\ \"\u003cSPOKEN_NOISE\u003e\" data/local/lang data/lang || exit 1; 上面shell脚本的目的是创建L.fst，音素模型，其中fst是Finite State Transducers（有限状态转换器）的缩写。找到这篇Kaldi学习笔记 – 构建字典FST脚本 – prepare_lang.sh 关键内容解析详细的说明了这个脚本的工作。而关于prepare_lang的一点理解给脚本进行了一些翻译和注释。 Kaldi中FST(Finite State Transducer)含义及其可视化 L.fst: 音素词典（Phonetic Dictionary or Lexicon）模型，phone symbols作为输入，word symbols作为输出，如图Figure 1所示。 L_disambig.fst是为了消除模棱两可（disambiguation）而引入的模型，表述为 the lexicon with disambiguation symbols。分歧的情况如：一个词是另一个词的前缀，cat 和 cats在同一个词典中，则需要\"k ae t #1\"； 有同音的词，red: “r eh d #1”, read: “r eh d #2”。 我一直疑惑lexiconp.txt是怎么生成的，查了好久。结果竟然只是一段在词和音素之间插入1.0的代码： if [[ ! -f $srcdir/lexiconp.txt ]]; then echo \"**Creating $srcdir/lexiconp.txt from $srcdir/lexicon.txt\" perl -ape 's/(\\S+\\s+)(.+)/${1}1.0\\t$2/;' \u003c $srcdir/lexicon.txt \u003e $srcdir/lexiconp.txt || exit 1; fi 那么L.fst是怎么得到的呢？ 通过make_lexicon_fst.py（现有的博客都说是.pl结尾，可能kaldi重构了）。还有一个消歧义的过程。具体的就看不懂了。解码图创建示例（测试阶段）里有较为详细的文档讲解。 5. LM training local/aishell_train_lms.sh || exit 1; 这个shell脚本读取data/local/train/text,data/local/dict/lexicon.txt 得到text的计数文件word.counts并以word.counts为基础添加lexicon.txt中的字（除了SIL）出现的次数到unigram.counts中。我就没深入看下去了，期间用到的脚本文件有:get_word_map.pl、train_lm.sh --arpa --lmtype 3gram-mincount $dir || exit 1;这个步骤的结果保存在data/local/lm/3gram-mincount/lm_unpruned.gz中。 6. G compilation, check LG composition utils/format_lm.sh data/lang data/local/lm/3gram-mincount/lm_unpruned.gz \\ data/local/dict/lexicon.txt data/lang_test || exit 1; 这个步骤是编译G.fst并将LG串联起来。 Kaldi中FST(Finite State Transducer)含义及其可视化 G.fst: 语言模型，大部分是FSA（finite state acceptor, i.e. 每个arc的输入输出是相同的），如图Figure 2所示。 kaldi 训练 aishell 解析 utils/format_lm.sh:上述的语言工具基于第三方工具，为ARPA-format,脚本的作业是将其转换为fst，方便与之前的字典fst(L.fst)结合，发挥fst的优势。脚本最后会检测G.fst中是否存在没有单词的空回环，如果存在会报错，因为这会导致后续HLG determinization的出现错误。 脚本utils/format_lm.sh解决把ARPA格式的语言模型转换成OpenFST格式类型。脚本用法如下： Usage: utils/format_lm.sh \u003clang_dir\u003e \u003cout_dir\u003e E.g.: utils/format_lm.sh data/lang data/local/lm/foo.kn.gz data/local/dict/lexi","date":"2020-11-23","objectID":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/:4:1","tags":["NLP","ASR"],"title":"学习Kaldi：中文Aishell项目（上）","uri":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/"},{"categories":["计算机"],"content":"训练 训练的环节开始我就读不懂了。主要是逻辑和概念不懂。也不浪费时间了。简单的去了解一下输入输出和功能。 1. MFCC 特征生成 这个环节和yesno项目的没有不同。主要就是获得train,test, dev三个集合的归一化的梅尔倒谱系数。最后修复排序错误，并会移除那些被指明需要特征数据或标注，但是却找不到被需要的数据的那些发音（utterances）。 2. 训练单音素模型 steps/train_mono.sh --cmd \"$train_cmd\" --nj 10 \\ data/train data/lang exp/mono || exit 1; 参考kaldi-GMM-HMM pipeline，上面的shell脚本主要是对齐音素和每一帧音频的。Kaldi 入门train_mono.sh详解、kaldi学习笔记 – 训练单音素（monophone）模型脚本 – steps/train_mono.sh都有讲一些。 对流程讲得最好的是： mkgraph 需要 lang_test 下的 L.fst G.fst phones.txt, words.txt , phones/silence.csl , phones/http://disambig.int 以及 exp/tri 下的 tree, final.mdl 在训练的job并行训练过程中，训练数据的各个子集合是分散到不同的处理器去进行训练，然后每轮迭代后会进行合并。 下面就讲一下训练的过程： 1.首先是初始化GMM，使用的脚本是/kaldi-trunk/src/gmmbin/gmm-init-mono，输出是0.mdl和tree文件； 2.compile training graphs,使用的脚本是/kaldi-trunk/source/bin/compile-training-graphs，输入是tree,0.mdl和L.fst,输出是fits.JOB.gz，其是在训练过程中构建graph的过程； 3.接下来是一个对齐的操作，kaldi-trunk/source/bin/align-equal-compiled； 4.然后是基于GMM的声学模型进行最大似然估计得过程，脚本为/kaldi-trunk/src/gmmbin/gmm-est； 5.然后进行迭代循环中进行操作，如果本步骤到了对齐的步骤，则调用脚本kaldi-kaldi/src/gmmbin/gmm-align-compiled； 6.重新估计GMM，累计状态，用脚本/kaldi-trunk/src/gmmbin/gmm-acc-states-ali；调用新生成的参数(高斯数)重新估计GMM，调用脚本/kaldi-trunk/src/gmmbin/gmm-est； 7.对分散在不同处理器上的结果进行合并，生成.mdl结果，调用脚本gmm-acc-sum； 8.增加高斯数，如果没有超过设定的迭代次数，则跳转到步骤5重新进行训练 最后生成的.mdl即为声学模型文件 在离线识别阶段，即可以调用utils/mkgraph.sh；来对刚刚生成的声学文件进行构图 之后解码，得到离线测试的识别率。 3. (Monophone decoding) 单音素解码 utils/mkgraph.sh data/lang_test exp/mono exp/mono/graph || exit 1; steps/decode.sh --cmd \"$decode_cmd\" --config conf/decode.config --nj 10 \\ exp/mono/graph data/dev exp/mono/decode_dev steps/decode.sh --cmd \"$decode_cmd\" --config conf/decode.config --nj 10 \\ exp/mono/graph data/test exp/mono/decode_test mkgraph.sh将L_disambig.fst 和 G.fst 复合生成LG.fst。中间经历了我看不懂的处理。最终生成用于解码的 HCLG.fst。 看不懂的部分 后面就已经看不懂了。 # Get alignments from monophone system. steps/align_si.sh --cmd \"$train_cmd\" --nj 10 \\ data/train data/lang exp/mono exp/mono_ali || exit 1; # train tri1 [first triphone pass] steps/train_deltas.sh --cmd \"$train_cmd\" \\ 2500 20000 data/train data/lang exp/mono_ali exp/tri1 || exit 1; # decode tri1 utils/mkgraph.sh data/lang_test exp/tri1 exp/tri1/graph || exit 1; steps/decode.sh --cmd \"$decode_cmd\" --config conf/decode.config --nj 10 \\ exp/tri1/graph data/dev exp/tri1/decode_dev steps/decode.sh --cmd \"$decode_cmd\" --config conf/decode.config --nj 10 \\ exp/tri1/graph data/test exp/tri1/decode_test # align tri1 steps/align_si.sh --cmd \"$train_cmd\" --nj 10 \\ data/train data/lang exp/tri1 exp/tri1_ali || exit 1; # train tri2 [delta+delta-deltas] steps/train_deltas.sh --cmd \"$train_cmd\" \\ 2500 20000 data/train data/lang exp/tri1_ali exp/tri2 || exit 1; # decode tri2 utils/mkgraph.sh data/lang_test exp/tri2 exp/tri2/graph steps/decode.sh --cmd \"$decode_cmd\" --config conf/decode.config --nj 10 \\ exp/tri2/graph data/dev exp/tri2/decode_dev steps/decode.sh --cmd \"$decode_cmd\" --config conf/decode.config --nj 10 \\ exp/tri2/graph data/test exp/tri2/decode_test # train and decode tri2b [LDA+MLLT] steps/align_si.sh --cmd \"$train_cmd\" --nj 10 \\ data/train data/lang exp/tri2 exp/tri2_ali || exit 1; # Train tri3a, which is LDA+MLLT, steps/train_lda_mllt.sh --cmd \"$train_cmd\" \\ 2500 20000 data/train data/lang exp/tri2_ali exp/tri3a || exit 1; utils/mkgraph.sh data/lang_test exp/tri3a exp/tri3a/graph || exit 1; steps/decode.sh --cmd \"$decode_cmd\" --nj 10 --config conf/decode.config \\ exp/tri3a/graph data/dev exp/tri3a/decode_dev steps/decode.sh --cmd \"$decode_cmd\" --nj 10 --config conf/decode.config \\ exp/tri3a/graph data/test exp/tri3a/decode_test # From now, we start building a more serious system (with SAT), and we'll # do the alignment with fMLLR. steps/align_fmllr.sh --cmd \"$train_cmd\" --nj 10 \\ data/train data/lang exp/tri3a exp/tri3a_ali || exit 1; steps/train_sat.sh --cmd \"$train_cmd\" \\ 2500 20000 data/train data/lang exp/tri3a_ali exp/tri4a || exit 1; utils/mkgraph.sh data/lang_test exp/tri4a exp/tri4a/graph steps/decode_fmllr.sh --cmd \"$decode_cmd\" --nj 10 --config conf/decode.config \\ exp/tri4a/graph data/dev exp/tr","date":"2020-11-23","objectID":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/:4:2","tags":["NLP","ASR"],"title":"学习Kaldi：中文Aishell项目（上）","uri":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/"},{"categories":["计算机"],"content":"获取结果 # getting results (see RESULTS file) for x in exp/*/decode_test; do [ -d $x ] \u0026\u0026 grep WER $x/cer_* | utils/best_wer.sh; done 2\u003e/dev/null for x in exp/*/*/decode_test; do [ -d $x ] \u0026\u0026 grep WER $x/cer_* | utils/best_wer.sh; done 2\u003e/dev/null exit 0; 和上一篇文章一样的步骤。 Kaldi入门：yesno项目 ","date":"2020-11-23","objectID":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/:4:3","tags":["NLP","ASR"],"title":"学习Kaldi：中文Aishell项目（上）","uri":"/posts/%E5%AD%A6%E4%B9%A0kaldi%E4%B8%AD%E6%96%87aishell%E9%A1%B9%E7%9B%AE%E4%B8%8A/"},{"categories":["计算机"],"content":"我的主力编程语言现在是Python，平时也会使用Python写一些小脚本做文件处理（更简单一些的操作会直接用Shell命令）。基本不会接触到GUI界面的编写。但是呢，对于我而言命令行是可行的方案，但是如果要把代码交给没有编程基础的人，并且没有相关的开发环境时。就需要GUI和打包技术了。最近就遇到一个情况需要开发一个类似图片直方图均衡的功能给和课题组合作的医生使用，工作的电脑是离线的，医生没有编程基础。 要求条件： 使用Python，快捷开发； GUI； 独立的EXE可执行文件。 技术栈： Numpy，用于对像素数组进行映射； Pillow，图像库，底层调用numpy； TkinterDND2使用Python内置的Tkinter的改进版，支持基础的code based UI和文件拖拽功能。使用conda安装。 我的开发环境是OS X，幸好之前一个老师分配的Windows虚拟机还能用。Python环境3.7.3。 ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:0:0","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["计算机"],"content":"第一版 支持选取图片文件夹，递归查找其中的jpg文件并处理。 ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:1:0","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["计算机"],"content":"文件夹选取功能 ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:1:1","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["计算机"],"content":"图片处理函数 ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:1:3","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["计算机"],"content":" 简单的对图片像素映射到0-255的范围。能够使得标本图片更容易标注。 ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:1:4","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["计算机"],"content":"恢复函数 ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:1:5","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["计算机"],"content":" 相当于图片处理函数的逆操作，在图片处理的时候保存了每一张图片的处理参数。 ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:1:6","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["计算机"],"content":"性能分析： ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:1:7","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["计算机"],"content":" 因为一个标本采集的图片有接近2000张，测试时预估大约需要8分钟才能完成一个标本的图片优化。而费 使用cProfile进行性能分析，61张图片要18秒多。平均一秒3张图片。主要的时间消耗是在转换成numpy矩阵、保存图片和图片处理函数。基本是不能够再优化的。那么就要从数据量方面考虑，是否每一张图片都需要优化并标注？其实不是的，每一个标本只需要选取最多10张进行标注，那么由医生选取并且拖放到指定界面会更快捷。 ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:1:8","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["计算机"],"content":"第二版 ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:2:0","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["计算机"],"content":" 第二版添加了拖放功能并且把文件夹选取的功能去掉了。可以拖放多个文件，并且会筛选处理其中的jpg文件。 PS: 连标题都懒得改。。 ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:3:0","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["计算机"],"content":"pyinstaller打包 使用pip 安装pyinstaller打包，pyinstaller是系统依赖的，在什么系统打包，在什么系统使用。坑很多。 ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:4:0","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["计算机"],"content":"总结 使用pyinstaller遇到几个bug。six，warm 打包太大了。有500MB。代码量180行。 加了Frame之后文件夹输入框就不更新了。可能的原因是pack和grid在frame和widge之间混用。或者混用Tkinter和TkinterDnD2。因为文件夹选取的方案被替换掉了。所以这个bug不再存在。 conda环境安装耗时较久。 还是java香。 ","date":"2020-11-23","objectID":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/:5:0","tags":["Python"],"title":"使用Python开发桌面应用的一个体验","uri":"/posts/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/"},{"categories":["个人"],"content":"我常用Todoist 管理自己的任务，用印象笔记存放感兴趣的文本和自己觉得需要保存的文本。 后来因为Notion的数据库特质吸引到我。所以整合之前的项目管理、任务管理和笔记文本管理在Notion之中。 Notion的缺点在于过于自由，需要加一个框架来使之符合项目管理、任务管理、文本笔记管理的功能。 使用前后端分离的方式，将整个Notion空间分为View和Model，用一些自定义的数据库来组织不同类型的数据，位于根目录Resources之下。 ","date":"2020-11-23","objectID":"/posts/%E4%BB%A5notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/:0:0","tags":["个人","知识管理"],"title":"以Notion为基础的自我管理体系","uri":"/posts/%E4%BB%A5notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/"},{"categories":["个人"],"content":"数据库 Resource Notes（笔记） Book（书籍） Video（想看的，看过的视频） People（人脉） Thing（事情，分为Task和Calendar） Tag（标签） Subscription（订阅服务） Project（基于项目的自我管理），与Things、note联系。 ","date":"2020-11-23","objectID":"/posts/%E4%BB%A5notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/:1:0","tags":["个人","知识管理"],"title":"以Notion为基础的自我管理体系","uri":"/posts/%E4%BB%A5notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/"},{"categories":["个人"],"content":"Dashboard 主要通过Dashboard这一个页面来管理自己当天的任务、任务收件箱和笔记。 ","date":"2020-11-23","objectID":"/posts/%E4%BB%A5notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/:2:0","tags":["个人","知识管理"],"title":"以Notion为基础的自我管理体系","uri":"/posts/%E4%BB%A5notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/"},{"categories":["个人"],"content":"善用过滤器和视图类型 数据库可以自选多种视图类型，如列表，日历，卡片，表格等。并且可以使用过滤功能。但是一个视图只能有一个过滤器。通过复制视图可以达到快速创建相同类型的视图和不同的过滤功能。 ","date":"2020-11-23","objectID":"/posts/%E4%BB%A5notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/:3:0","tags":["个人","知识管理"],"title":"以Notion为基础的自我管理体系","uri":"/posts/%E4%BB%A5notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/"},{"categories":["个人"],"content":"适用情况与不适用情况 Notion到目前为止都不能避免的两个大山： GFW Web App 第一点导致很难让其他人访问，导致作为团队共享或者公开访问需要较大的门槛。 Notion到现在为止都是以HTML，CSS，JS为基础的。所谓的客户端都是网页，并没有多强的离线功能，更别提下载某一个页面。与系统的整合很差。没有单独的页面快捷入口，比起Todoist和印象笔记存在较大的稳定问题。 如果网络环境不好，要做好不能够随时访问重要信息的准备！ 所以我会有一个Tag叫Save to Evernote来手动将重要的信息保存到印象笔记并且离线下来，遇到任务也会先放到Todoist中，等能连上网的时候再同步。 原文链接：https://www.notion.so/imchenmin/Notion-d7b4ef1b46aa4ef7b73dc3fb25d5a2d1 ","date":"2020-11-23","objectID":"/posts/%E4%BB%A5notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/:4:0","tags":["个人","知识管理"],"title":"以Notion为基础的自我管理体系","uri":"/posts/%E4%BB%A5notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/"},{"categories":["计算机"],"content":"帮同学的实验室配置静态IP，将其中的流程和关键记录下来。 校园网内使用DHCP来分配IP地址，有效期为2天，如果两天之内设备未续租，IP地址会被收回。 实验室的服务器需要远程登陆，需要一个静态IP来保证服务器的可访问性。 在申请了几个静态IP之后，会获得一组数据。1) 172.xxx.xxx.xxx、2) 255.255.255.0、3) 172.xxx.xxx.254、4) vlanxx。其中1）是静态IP的地址，2）是子网掩码，也可以用24表示。3）网关地址，4）交换机的vlan接口，由交换机管理员配置。 学校中由网络中心运营管理交换机，需要先联系工程师在网关中添加vlanxx接口，并且把服务器的所有MAC地址绑定静态IP地址组。 服务器的操作系统和版本是Ubuntu 18.04 server。网络管理使用netplan。之前同学装了gnome-shell。我先尝试使用简易桌面自带的网络管理程序，ifconfig -a发现对网卡配置不起作用。 直接修改netplan程序位于\\etc\\netplan\\01-netcfg.yaml。 当时该文件基本的结构如下： network: version: 2 renderer: networkd ethernets: eno1: dhcp4: true bridges: vir0br: interfaces: [eno1] dhcp4: true 需要注意的就是eno1和vir0br。其中dhcp4代表着是否使用ipv4版本的dhcp地址分配。 vir0br是https://virt-manager.org/虚拟机管理器NAT模式下的网桥接口。服务器中通过virt-manager运行着windows 系统。 配置静态ip需要修改eno1的配置。 eno1: dhcp4: no addresses: [172.xxx.xxx.xxx/24] gateway4: 172.xxx.xxx.254 nameservers: addresses: [8.8.8.8, 8.8.4.4] 然后netplan apply。接着ifconfig -a 查看网卡ip是否更改，如果没有更改，不用着急。很可能是配置文件的问题。而不是需要重启或者sudo service networking restart重启网卡。 需要注意的是这里有一个bridge。bridge是一个虚拟网络设备，具有网络设备的特征，可以配置IP，MAC地址等。bridge不分接入进来的设备是虚拟的还是物理的，当eno1加入vir0br之后，从外面网络收到的数据包将无条件的转发给vir0br，自己变成一根网线。先用brctl show查看网桥状态然后.ifconfig \u003c网桥名\u003e down, brctl delbr \u003c网桥名\u003e删除网桥，将01-netcf.yaml中的bridge 部分删掉。（但是会造成虚拟机网络异常）。 重新netplan apply，完成静态IP的配置。 对于windows虚拟机的网络配置还在检索学习中。网上较少Linux寄主机，Windows虚拟机的配置情况。 ","date":"2020-11-23","objectID":"/posts/ubuntu-18.04%E9%9D%99%E6%80%81ip%E8%AE%BE%E7%BD%AE%E5%92%8C%E9%81%87%E5%88%B0%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E5%8D%A1%E9%97%AE%E9%A2%98/:0:0","tags":["计算机网络","Linux"],"title":"Ubuntu 18.04静态IP设置和遇到的虚拟机网卡问题","uri":"/posts/ubuntu-18.04%E9%9D%99%E6%80%81ip%E8%AE%BE%E7%BD%AE%E5%92%8C%E9%81%87%E5%88%B0%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E5%8D%A1%E9%97%AE%E9%A2%98/"},{"categories":["计算机"],"content":"使用K-means做视频图像分割的作业的时候，遇到一个问题值得记录。 该代码的功能是使用K-means做图像分割并保存图像与视频。 遇到的问题是kmean之后得到的是每一个像素点的分类标签，需要将这些标签可视化成为分割(Segmentation)的结果视频。一开始没有直接找到相关的函数，搜索查询后给的建议都是使用matlibplot的plt.imshow()函数来实现，但是我不想要每次保存成为图片再转成视频，考虑到opencv-python的底层使用numpy.array来表述图像的。一个BGR图像相当于一个3维uint8数组（w,h,c)。要做的就是生成一个标签到像素的映射关系。这里我用的是matplotlib.cm color map 功能。 x = np.linspace(0.0, 1.0, 10) rgb = cm.get_cmap(plt.get_cmap('Set1'))(x)[np.newaxis, :, :3][0] import numpy as np from numpy.matlib import repmat from sklearn.preprocessing import normalize import matplotlib.pyplot as plt from matplotlib import cm from sklearn.cluster import KMeans import cv2 from PIL import Image n_cl=5 videoCapture = cv2.VideoCapture('road_video.mov') fps = videoCapture.get(cv2.CAP_PROP_FPS) size = (int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)), int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT))) videoWriter = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), (fps/10), size) def kmeans(data, n_cl, verbose=True): n_samples, dim = data.shape centers = data[np.random.choice(range(n_samples), size=n_cl)] old_labels = np.zeros(shape=n_cl) while True: distances = np.zeros((n_samples, n_cl)) for cluster_idx, cluster in enumerate(centers): distances[:, cluster_idx] = np.sum(np.square(data - repmat(cluster, n_samples, 1)), axis=1) new_labels = np.argmin(distances, axis=1) for l in range(0, n_cl): centers[l] = np.mean(data[new_labels==l], axis=0) if verbose: fig, ax = plt.subplots() ax.scatter(data[:, 0], data[:, 1], cluster=new_labels, s=40) ax.plot(centers[:, 0], centers[:, 1], 'r*', markersize=20) plt.waitforbuttonpress() plt.close() if np.array_equal(new_labels, old_labels): break old_labels = new_labels return new_labels count = 0 x = np.linspace(0.0, 1.0, 10) rgb = cm.get_cmap(plt.get_cmap('Set1'))(x)[np.newaxis, :, :3][0] while True: print(count) count += 1 # load the frame success, frame = videoCapture.read() if not success: break img = np.float32(frame) h,w,c = img.shape # print(h,w,c) # add coordinates row_indexes = np.arange(0, h) col_indexes = np.arange(0, w) coordinates = np.zeros(shape=(h,w,2)) coordinates[..., 0] = normalize(repmat(row_indexes, w, 1).T) coordinates[..., 1] = normalize(repmat(col_indexes, h, 1)) data = np.concatenate((img, coordinates), axis=-1) data = np.reshape(data, newshape=(w *h, 5)) labels = kmeans(data, n_cl=n_cl, verbose=False) print('after') labels = labels.flatten() segmented_image = rgb[labels.flatten()] # print(segmented_image) segmented_image = segmented_image.reshape(img.shape) plt.imshow(segmented_image) # # plt.imshow(np.reshape(labels, (h, w)), cmap=\"hsv\") plt.savefig(\"lab9/\"+str(count-1)) segmented_image = segmented_image *255 segmented_image = segmented_image.astype('uint8') videoWriter.write(segmented_image) videoWriter.release() videoCapture.release() ","date":"2020-11-22","objectID":"/posts/opencv%E5%92%8Cnumpy%E7%AC%94%E8%AE%B0/:0:0","tags":["OpenCV","Numpy","Python"],"title":"OpenCV和numpy笔记","uri":"/posts/opencv%E5%92%8Cnumpy%E7%AC%94%E8%AE%B0/"},{"categories":["计算机"],"content":"参考网页 https://blog.csdn.net/llh_1178/article/details/77833447 https://docs.opencv.org/3.4/d4/dba/classcv_1_1viz_1_1Color.html https://realpython.com/python-opencv-color-spaces/ https://www.thepythoncode.com/article/kmeans-for-image-segmentation-opencv-python https://pvss.github.io/Opencv+Python.html https://stackoverflow.com/questions/9280653/writing-numpy-arrays-using-cv2-videowriter ","date":"2020-11-22","objectID":"/posts/opencv%E5%92%8Cnumpy%E7%AC%94%E8%AE%B0/:1:0","tags":["OpenCV","Numpy","Python"],"title":"OpenCV和numpy笔记","uri":"/posts/opencv%E5%92%8Cnumpy%E7%AC%94%E8%AE%B0/"},{"categories":["计算机"],"content":"课题组要部署一个云服务，之前用的是我个人申请的学生版服务器，价格优惠。快到期需要续费，但是优惠版的服务器不能够继续以优惠价格续费，正常的价格是一千多每年。所以我决定新申请一个优惠版服务器，然后迁移Postgres数据库和部署的web server。 基本步骤是购买新服务器（Ubuntu18.04版本），密码重设，为了方便登录也可以设置ssh免密码登录。 ","date":"2020-11-21","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:0:0","tags":["运维","Postgres","Linux"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"安装配置Postgres 我觉得Postgres比MySQL好的一点在于其开源。且能实现数据库的基本功能。 ","date":"2020-11-21","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:1:0","tags":["运维","Postgres","Linux"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"服务器安装Postgres sudo apt-get install postgresql postgresql-client 可以在本机安装一个postgres-client，免得在两个服务器之间来回登录。 ","date":"2020-11-21","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:1:1","tags":["运维","Postgres","Linux"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"配置postgres数据库账号和远程连接 登录新服务器，设置linux中的postgres用户密码 sudo passwd postgres或者sudo -i -u postgres，免密码登录。 设置postgres 中postgres用户密码(以postgres用户登录) psql进入数据库clinet软件 postgres \\password设置数据库管理员postgres的密码 ","date":"2020-11-21","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:1:2","tags":["运维","Postgres","Linux"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"远程连接设置 修改Postgres远程连接允许 sudo vim /etc/postgres/10/main/postgres.conf， 修改listen_addresses那一行为listen_addresses = '*'（有的公司要求不允许数据库开放外网访问，请谨慎该选项）。 修改远程登录选项 vim /etc/postgres/10/main/pg_dba.conf 添加新行 host all all 0.0.0.0/0 md5 (不要使用trust，除非你想任何人能够访问你的数据库内容) 重启服务以应用刚刚的修改 sudo service postgresql restart 参考 ","date":"2020-11-21","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:1:3","tags":["运维","Postgres","Linux"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"数据库迁移 Postgres 提供导出数据库数据和结构的程序。有两种方法，一种是在本机安装psql程序，新旧服务器都进行上面的远程连接设置，然后本机连接源服务器数据库dump备份文件，然后本机连接目标服务器数据库导入数据；另外一种是登录源服务器dump备份文件，再导出到目标服务器，在目标服务器执行导入操作。我使用的是比较麻烦的第二种。 ","date":"2020-11-21","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:2:0","tags":["运维","Postgres","Linux"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"备份数据库 pg_dump -h (ip or localhost) -U postgres databasename \u003e databasename.bak 我是在服务器本地进行的操作，所以可以使用localhost。 ","date":"2020-11-21","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:2:1","tags":["运维","Postgres","Linux"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"恢复数据库 恢复数据库指令不会创建新的数据库，所以需要先行在新的数据库中创建数据库 create database databasename; 然后执行psql -h localhost -U postgres -d databasename \u003c databasename.bak恢复数据库。 参考 ","date":"2020-11-21","objectID":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/:2:2","tags":["运维","Postgres","Linux"],"title":"新服务器迁移postgres数据库","uri":"/posts/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["计算机"],"content":"这个学期选了一门自然语言处理课，结果这门课主要的研究课题是自动语音识别（ASR）。既然入了这个坑。就先好好了解一下如何做ASR吧。 老师Tom Ko要求使用Kaldi这个工具来做ASR。课上到一半才知道Kaldi中有几千行的脚本代码是老师提交的。好吧，脚本好难的。 为了入门Kaldi，课程的第5次Lab是一个mini projec: yesno 首先要下载并编译Kaldi，安装的过程不是我的学习重点，可以先参考Kaldi的下载安装与编译，在漫长的编译过程之后假设已经安装好了Kaldi。 ","date":"2020-05-01","objectID":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/:0:0","tags":["NLP","ASR"],"title":"Kaldi入门(一):yesno项目","uri":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/"},{"categories":["计算机"],"content":"项目目录结构 yesno项目的脚本和README都在kaldi/egs/yesno之下。 README.txt文件中包含数据集描述： The \"yesno\" corpus is a very small dataset of recordings of one individual saying yes or no multiple times per recording, in Hebrew. It is available from http://www.openslr.org/1. It is mainly included here as an easy way to test out the Kaldi scripts. The test set is perfectly recognized at the monophone stage, so the dataset is not exactly challenging. The scripts are in s5/. 数据脚本路径： kaldi/egs/yesno/s5。在下面执行的很多操作都可以直接调用已经写好的脚本来执行，之所以深入到具体的流程中是为了加强对ASR流程的理解。 ","date":"2020-05-01","objectID":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/:1:0","tags":["NLP","ASR"],"title":"Kaldi入门(一):yesno项目","uri":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/"},{"categories":["计算机"],"content":"下载数据集 第一步是从网络上下载数据集文件waves_yesno.tar.gz到s5/路径下并解压。 原始的数据是60个.wav文件。文件名是八个用下划线分隔的01组合。需要将音频数据转化成kaldi能够处理的格式。 ","date":"2020-05-01","objectID":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/:2:0","tags":["NLP","ASR"],"title":"Kaldi入门(一):yesno项目","uri":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/"},{"categories":["计算机"],"content":"转换成Kaldi能处理的格式 下载完数据集后，将数据集划分为31个训练，30个测试（数量大致相当）。在s5/下创建data文件夹，把划分好的音频文件放入train_yesno和test_yesno。 Kaldi使用以下几个文件来表示数据： Text 音频的文本记录。每一个音频文件一行。格式为\u003cutt_id\u003e \u003ctranscript\u003e。\u003cutt_id\u003e为音频的id，一般用不带扩展名的文件名表示。utt_id在wav.scp文件中与具体的文件映射。是音频对应的文字。 wav.scp 将文件映射到唯一的utt_id。 格式为\u003cutt_id\u003e \u003cpath or command to get wave file\u003e 第二个参数既可以是对应utt_id的音频文件路径，也可以是能够获得音频文件的指令。 utt2spk 对于每一个音频文件，标记是哪一个人发音的。因为yesno数据集中只有一个发音者，用global来表示所有的utt_id 文件内每一行的格式为\u003cutt_id\u003e \u003cspeaker_id\u003e spk2utt 和3反过来。文件内每一行对应一个发音者，第一个是speaker的id，后面用空格分隔开60个utt_id。格式为\u003cspeaker_id\u003e \u003cutt_id1\u003e \u003cutt_id2\u003e ... 本步骤可直接调用脚本： cd kaldi/egs/yesno/s5 local/prepare_data.sh waves_yesno 读了一下prepare_data.sh的脚本 #!/usr/bin/env bash mkdir -p data/local local=`pwd`/local scripts=`pwd`/scripts export PATH=$PATH:`pwd`/../../../tools/irstlm/bin echo \"Preparing train and test data\" train_base_name=train_yesno test_base_name=test_yesno waves_dir=$1 ls -1 $waves_dir \u003e data/local/waves_all.list cd data/local ../../local/create_yesno_waves_test_train.pl waves_all.list waves.test waves.train ../../local/create_yesno_wav_scp.pl ${waves_dir} waves.test \u003e ${test_base_name}_wav.scp ../../local/create_yesno_wav_scp.pl ${waves_dir} waves.train \u003e ${train_base_name}_wav.scp ../../local/create_yesno_txt.pl waves.test \u003e ${test_base_name}.txt ../../local/create_yesno_txt.pl waves.train \u003e ${train_base_name}.txt cp ../../input/task.arpabo lm_tg.arpa cd ../.. # This stage was copied from WSJ example for x in train_yesno test_yesno; do mkdir -p data/$x cp data/local/${x}_wav.scp data/$x/wav.scp cp data/local/$x.txt data/$x/text cat data/$x/text | awk '{printf(\"%s global\\n\", $1);}' \u003e data/$x/utt2spk utils/utt2spk_to_spk2utt.pl \u003cdata/$x/utt2spk \u003edata/$x/spk2utt done ","date":"2020-05-01","objectID":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/:3:0","tags":["NLP","ASR"],"title":"Kaldi入门(一):yesno项目","uri":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/"},{"categories":["计算机"],"content":"建立词典 对于当前项目，我们只有两个词 Ken(yes) 和 Lo（no)。但是在真实的语言中，词的数量不可能这么少，并且还有停顿和环境噪声。kaldi将这些非语言的声音称作slience（SIL）。 加上SIL一共需要三个词来表示当前这个yesno语言模型。 调用脚本： local/prepare_dict.sh 将会在s5/data/local/dict中看到新生成的5个文件。 lexicon.txt \u003cSIL\u003e SIL YES Y NO N lexicon_words.txt 比1少第一行 nonsilence_phones.txt Y N silence_phones.txt SIL optional_silence.txt 和4一样 这个脚本本身只是将input文件夹下面的lexicon_nosil.txt，lexicon.txt， phones.txt复制到dict所在目录，并且加上SIL。 ","date":"2020-05-01","objectID":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/:4:0","tags":["NLP","ASR"],"title":"Kaldi入门(一):yesno项目","uri":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/"},{"categories":["计算机"],"content":"语言模型 接下来要做语言模型。 项目提供了一个一元的语言模型。然而我们需要将这个模型转换成一个WFST（一种有穷自动机） 执行: utils/prepare_lang.sh --position-dependent-phones false data/local/dict/ \"\u003cSIL\u003e\" data/local/lang/ data/lang local/prepare_lm.sh prepare_lang.sh的开头注释如下： # This script prepares a directory such as data/lang/, in the standard format, # given a source directory containing a dictionary lexicon.txt in a form like: # word phone1 phone2 ... phoneN # per line (alternate prons would be separate lines), or a dictionary with probabilities # called lexiconp.txt in a form: # word pron-prob phone1 phone2 ... phoneN # (with 0.0 \u003c pron-prob \u003c= 1.0); note: if lexiconp.txt exists, we use it even if # lexicon.txt exists. # and also files silence_phones.txt, nonsilence_phones.txt, optional_silence.txt # and extra_questions.txt # Here, silence_phones.txt and nonsilence_phones.txt are lists of silence and # non-silence phones respectively (where silence includes various kinds of # noise, laugh, cough, filled pauses etc., and nonsilence phones includes the # \"real\" phones.) # In each line of those files is a list of phones, and the phones on each line # are assumed to correspond to the same \"base phone\", i.e. they will be # different stress or tone variations of the same basic phone. # The file \"optional_silence.txt\" contains just a single phone (typically SIL) # which is used for optional silence in the lexicon. # extra_questions.txt might be empty; typically will consist of lists of phones, # all members of each list with the same stress or tone; and also possibly a # list for the silence phones. This will augment the automatically generated # questions (note: the automatically generated ones will treat all the # stress/tone versions of a phone the same, so will not \"get to ask\" about # stress or tone). 通过阅读脚本和脚本中的注释。可以知道prepare_lang.sh的用法 Usage: utils/prepare_lang.sh \u003cdict-src-dir\u003e \u003coov-dict-entry\u003e \u003ctmp-dir\u003e \u003clang-dir\u003e e.g.: utils/prepare_lang.sh data/local/dict \u003cSPOKEN_NOISE\u003e data/local/lang data/lang --position-dependent-phones (true|false) # default: true; if true, use _B, _E, _S \u0026 _I 是我们在上一部分生成的词典目录。需要包含lexico.txt，extra_questions.txt，nonsilence_phones.txt，optional_silence.txt silence_phones.txt。 position_dependent_phones参数为false，导致解码后不能算出单词边界。很多的脚本，特别是评分脚本将不能正常运行。 第二个指令将语言模型转换成G.fst格式并保存在data/lang_test_tg 目录下。 这个脚本的核心内容是调用了arpa2fst和fstisstochastic，再创建了G.fst之后检查是否有空字符（,之类的）的循环。 arpa2fst --disambig-symbol=#0 --read-symbol-table=$test/words.txt input/task.arpabo $test/G.fst fstisstochastic $test/G.fst arpa2fst 原理详解 arpa文件可以很容易地表示任意n-gram语言模型，不过在实际中n通常等于3、4或者5。arpa文件的每一行表示一个文法项，它通常包含三部分内容：probability word(s) [backoff probability]。probability表示该词或词组发生的概率，word(s)表示具体的词或者词组。backoff probablitiy是可选项，表示回退概率。 在yesno这个toy project中只使用1元的语言模型。对应的arpa文件在input/task.arpabo \\data\\ ngram 1=4 \\1-grams: -1 NO -1 YES -99 \u003cs\u003e -1 \u003c/s\u003e \\end\\ fstisstochastic命令则如同其名字的含义一样，用来检查G.fst是否是随机的。 在s5/data/lang目录下会出现： phones.txt:将phone转换成数字。其中#0，#1是空字，用来表示句子的开头和结尾。 是一个特别的含义表示这个弧上没有符号。 \u003ceps\u003e 0 SIL 1 Y 2 N 3 #0 4 #1 5 words.txt \u003ceps\u003e 0 \u003cSIL\u003e 1 NO 2 YES 3 #0 4 \u003cs\u003e 5 \u003c/s\u003e 6 L_disambig.fst, L.fst: the dict can be recognized by Kaldi topo: phone states transition(HMM) oov: out of vocabulary. 仅包含\u003cSIL\u003e phones: some information about phones ","date":"2020-05-01","objectID":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/:5:0","tags":["NLP","ASR"],"title":"Kaldi入门(一):yesno项目","uri":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/"},{"categories":["计算机"],"content":"特征提取和训练 MFCC特征提取和GMM-HMM建模 提取梅尔倒谱系数 steps/make_mfcc.sh --nj $num $input_dir $log_dir $output_dir 语音信号处理（二）—— MFCC详解 梅尔倒谱系数是一种非线性的时频表示法，其应用了人耳对低频声音的听觉敏感度更高的原理。 接着正则化倒谱特征 steps/compute_cmvn_stats.sh utils/fix_data_dir.sh $input_dir Kaldi中的特征提取(二）- 特征变换 对训练集和测试集做同样的操作。 这里我采用的参数是 $num=1 $output_dir=mfcc 那么结果将会保存在mfcc文件夹下。 cmvn_test_yesno.ark cmvn_test_yesno.scp cmvn_train_yesno.ark cmvn_train_yesno.scp。 ark文件包含特征向量（用cat打开是乱码），scp文件是关系文件，从发音者到ark文件的对应。 也可以直接跑脚本： num=1 output_dir=mfcc for x in train_yesno test_yesno; do steps/make_mfcc.sh --nj 1 data/$x exp/make_mfcc/$x mfcc steps/compute_cmvn_stats.sh data/$x exp/make_mfcc/$x mfcc utils/fix_data_dir.sh data/$x done ","date":"2020-05-01","objectID":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/:6:0","tags":["NLP","ASR"],"title":"Kaldi入门(一):yesno项目","uri":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/"},{"categories":["计算机"],"content":"单音素模型训练 steps/train_mono.sh —nj $N —cmd $MAIN_CMD $DATA_DIR $LANG_DIR $OUTPUT_DIR 参数说明： —nj：job的数量，来自同一个speaker的语音不能并行处理。所以在本项目中只能选择为1。 —cmd：为了使用本机的资源，调用”utils/run.pl” 运行脚本： train_cmd=\"utils/run.pl\" steps/train_mono.sh --nj 1 --cmd \"$train_cmd\" \\ --totgauss 400 \\ data/train_yesno data/lang exp/mono0a 到现在我们已经完成了模型的训练。 ","date":"2020-05-01","objectID":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/:7:0","tags":["NLP","ASR"],"title":"Kaldi入门(一):yesno项目","uri":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/"},{"categories":["计算机"],"content":"解码和测试 接下来用测试集来验证一下模型的准确与否。 第一步是创建一个全连接的FST网络。 utils/mkgraph.sh data/lang_test_tg exp/mono0a exp/mono0a/graph_tgpr 这个指令背后的脚本很长。基本上做的事情是创建以一个HCLG（HMM+Context+Lexicon+Grammer）的解码器并保存在exp/mono0a/graph_tgpr中。 还记得我们的每一条语音都是8个连续的Ken或Lo吗(Ken，Lo是希伯来语的yes no）?训练好的模型的工作就是找出这8个词的顺序。 steps/decode.sh [options] \u003cgraph-dir\u003e \u003cdata-dir\u003e \u003cdecode-dir\u003e用来寻找每一个测试音频的最佳路径 decode_cmd=\"utils/run.pl\" steps/decode.sh --nj 1 --cmd \"$decode_cmd\" \\ exp/mono0a/graph_tgpr data/test_yesno exp/mono0a/decode_test_yesno 最后是查看结果的环节。 在decode.sh内部最后会调用score.sh，这个脚本则生成预测的结果并且计算测试集Word error rate（WER）。 调用下列命令可以看到最好的效果： for x in exp/*/decode*; do [ -d $x ] \u0026\u0026 grep WER $x/wer_* | utils/best_wer.sh; done %WER 0.00 [ 0 / 232, 0 ins, 0 del, 0 sub ] exp/mono0a/decode_test_yesno/wer_10_0.0 解读一下结果，花了很长时间才弄懂这些东西是什么意思。 WER后跟着的0.00是说字的错误率为0，即准确率为100%。 测试集一共29条音频，每条音频有8个字（单音素的字）。一共232个字。 参考Stanford的cs224s-17.lec04.pdf 而wer结果文件中的10和0.0分别是lmwt(Language Weight)和wip(word insertion penalty，词插入惩罚)。lmwt用来平衡LM（语言模型）在多大程度上帮助AM（语音模型）至于wip： word insertion penalty, 简写WIP, 是HMM识别匹配过程中用于设置句长的一个参数，可以用来调节生成句子中的单词个数，当前主流的语音识别系统主要采用的都是音素识别，即根据单词的音标而不是单词来进行匹配，这就导致了，在识别过程中，可能很难确定单词的gap，如果让系统自由识别，根据参数初始化的模型来进行匹配的话有可能会生成一些诡异的由长单词构成的句子，或者有很多短单词构成的句子，这些匹配率很低的句子对HMM参数的优化作用很小，同时也很大概率会导致学习速率奇慢或者局部最优解这样的问题，所以通过设置这个参数来得到一些更符合语义结构的生成片段。 最后，我们调用的所有脚本都在run.sh中。 ","date":"2020-05-01","objectID":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/:8:0","tags":["NLP","ASR"],"title":"Kaldi入门(一):yesno项目","uri":"/posts/kaldi%E5%85%A5%E9%97%A8%E4%B8%80yesno%E9%A1%B9%E7%9B%AE/"},{"categories":["计算机"],"content":"在编写一个Django项目的时候有定时备份数据文件的需求。因为项目运行在云服务器中，担心的是服务器挂掉，所以备份的地方不能是同一台服务器。在这个项目里自己去建一个服务器来管理备份数据显得没有必要。目前网络存储提供商有许多家，我选取的方案是编写python定时程序连接支持WebDAV协议的网盘，例如坚果云和owncloud。 分为两部分： Python同步代码编写 Django定时任务编写 ","date":"2020-01-10","objectID":"/posts/python%E7%A8%8B%E5%BA%8F%E5%90%8C%E6%AD%A5webdav%E7%BD%91%E7%9B%98%E5%9D%9A%E6%9E%9C%E4%BA%91owncloud/:0:0","tags":["Python"],"title":"python程序同步webdav网盘（坚果云、owncloud)","uri":"/posts/python%E7%A8%8B%E5%BA%8F%E5%90%8C%E6%AD%A5webdav%E7%BD%91%E7%9B%98%E5%9D%9A%E6%9E%9C%E4%BA%91owncloud/"},{"categories":["计算机"],"content":"Python同步代码编写 使用webdavclient3库来处理webDAV协议的部分。先安装： pip install webdavclient3 然后在自己的项目的某个地方建立一个py文件。我选的是[项目目录]\\utils\\backup\\backup.py 编写python代码： from webdav3.client import Client from datetime import datetime from webdav3.exceptions import LocalResourceNotFound import math # invoke this function every day. def upload(): options = { 'webdav_hostname': \"网盘地址，如果是坚果云，不能只输入/dav/路径，似乎这个文件夹不能访问，在下面再建一个文件夹，比如backup。网址中需要有backup的地址比如https://dav.jianguoyun.com/dav/backup\", 'webdav_login': \"用户名\", 'webdav_password': \"密码，如果是坚果云填写应用密码\", 'disable_check': True, #有的网盘不支持check功能 } client = Client(options) # 我选择用时间戳为备份文件命名 file_name = str(math.floor(datetime.now().timestamp())) + '.bak' try: # 写死的路径，第一个参数是网盘地址 client.upload('backup/' + file_name, '本地地址，绝对路径') # 打印结果，之后会重定向到log print('upload at ' + file_name) except LocalResourceNotFound as exception: print('An error happen: LocalResourceNotFound ---' + file_name) # 如果是直接调用文件，执行upload() if __name__ == '__main__': print('run upload') upload() Python的代码相对简短。只需要在服务器的命令行执行python upload.py，备份文件自动上传到网盘。然而还不完整，这个程序的目的是定期执行。接下来结合Django的定期执行接口做到每日备份。 ","date":"2020-01-10","objectID":"/posts/python%E7%A8%8B%E5%BA%8F%E5%90%8C%E6%AD%A5webdav%E7%BD%91%E7%9B%98%E5%9D%9A%E6%9E%9C%E4%BA%91owncloud/:1:0","tags":["Python"],"title":"python程序同步webdav网盘（坚果云、owncloud)","uri":"/posts/python%E7%A8%8B%E5%BA%8F%E5%90%8C%E6%AD%A5webdav%E7%BD%91%E7%9B%98%E5%9D%9A%E6%9E%9C%E4%BA%91owncloud/"},{"categories":["计算机"],"content":"Django定时任务编写 Django是目前很流行的python web服务框架。通过django自带的命令创建project和app（这一部分不讲）。 当项目建好后，使用python manage.py可以运行项目、数据库代码整合。开发者可以通过继承BaseCommand类来自定义命令，然后再通过django_crontab定期执行命令。或者不通过自定义命令，直接使用django_crontab定期执行函数。 ","date":"2020-01-10","objectID":"/posts/python%E7%A8%8B%E5%BA%8F%E5%90%8C%E6%AD%A5webdav%E7%BD%91%E7%9B%98%E5%9D%9A%E6%9E%9C%E4%BA%91owncloud/:2:0","tags":["Python"],"title":"python程序同步webdav网盘（坚果云、owncloud)","uri":"/posts/python%E7%A8%8B%E5%BA%8F%E5%90%8C%E6%AD%A5webdav%E7%BD%91%E7%9B%98%E5%9D%9A%E6%9E%9C%E4%BA%91owncloud/"},{"categories":["计算机"],"content":"创建backupCmd命令 在之前创建的app下新建management/commands目录，在该目录下新建backupCmd.py from django.core.management.base import BaseCommand from utils.backup.backup import upload class Command(BaseCommand): def handle(self, *args, **options): upload() 当完成后，在项目根目录下执行python manage.py backupCmd就可以单次执行程序了。 在setting.py尾部添加: # 运行定时函数，每天1点运行。 CRONJOBS = [ ('0 01 * * *', 'utils.backup.backup','\u003e\u003e ~/test_crontab.log') ] 或 # 运行定时命令， CRONJOBS = [ ('*/1 * * * *', 'django.core.management.call_command', ['backupCmd'], {}, '\u003e\u003e ~/test_crontab.log'), ] 然后执行python manage.py crontab add，定时任务加入其中。 当时间到达的时候，程序将自动运行。日志会输出到~/test_crontab.log中。 linux中的定时任务crontab的语法如下: * * * * * command 分钟(0-59) 小时(0-23) 每个月的哪一天(1-31) 月份(1-12) 周几(0-6) shell脚本或者命令 对于使用到的网盘，希望能够付费支持一下。 ","date":"2020-01-10","objectID":"/posts/python%E7%A8%8B%E5%BA%8F%E5%90%8C%E6%AD%A5webdav%E7%BD%91%E7%9B%98%E5%9D%9A%E6%9E%9C%E4%BA%91owncloud/:2:1","tags":["Python"],"title":"python程序同步webdav网盘（坚果云、owncloud)","uri":"/posts/python%E7%A8%8B%E5%BA%8F%E5%90%8C%E6%AD%A5webdav%E7%BD%91%E7%9B%98%E5%9D%9A%E6%9E%9C%E4%BA%91owncloud/"},{"categories":["计算机"],"content":"计算机视觉课Assigment2的内容. 要求写出一个图像的过滤器出来。 ","date":"2019-09-27","objectID":"/posts/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/:0:0","tags":["Python"],"title":"用python写一个过滤器","uri":"/posts/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"categories":["计算机"],"content":"要求 **Image Filtering.**Image filtering (or convolution) is a fundamental image processing tool. You will be writing your own function to implement image filtering from scratch. More specifically, you will implement my_imfilter()which imitates the filter2Dfunction in the OpenCV library. As specified in student_code.py, your filtering algorithm must (1) support grayscale and color images (2) support arbitrary shaped filters, as long as both dimensions are odd (e.g. 7x9 filters but not 4x5 filters) (3) pad the input image with zeros or reflected image content (4) return a filtered image which is the same resolution as the input image. 使用numpy，PIL。 ","date":"2019-09-27","objectID":"/posts/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/:1:0","tags":["Python"],"title":"用python写一个过滤器","uri":"/posts/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"categories":["计算机"],"content":"步骤： 导入图像（不属于本次任务） 生成过滤核（不属于本次任务） padding calculate normalization（不属于本次任务，即假设过滤核和图像已经做好了正则化） 截断 ","date":"2019-09-27","objectID":"/posts/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/:2:0","tags":["Python"],"title":"用python写一个过滤器","uri":"/posts/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"categories":["计算机"],"content":"函数定义 图像过滤器的核心是一个function，函数的定义 def my_imfilter(image, filter) return filtered_image ","date":"2019-09-27","objectID":"/posts/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/:3:0","tags":["Python"],"title":"用python写一个过滤器","uri":"/posts/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"categories":["计算机"],"content":"设计思路 输入的图像为image，image可以为黑白或者RGB彩色。（channel=1 or channel=3) 所以输入的image.ndim可能为2或者为3. 第一部分代码需要判断黑白和彩色的情况. 图片过滤器会将原图片的尺寸缩小,因为进行卷积操作是将原图像的一个矩阵框中的点和过滤核相乘后在求和得到新图像的一个点的值。 【公式和图像】 假设原始图像的高和宽为img_h, img_w，过滤核的大小为filter_h, filter_w。这里有一个条件过滤核的长宽都必须为为奇数。（为什么呢？）那么除掉最中心的像素外，过滤核可以被分为四等份。每一部分的长宽(padding)为 pad_h = (filter_h-1)/2和pad_w = (filter_w-1)/2 那么输出的尺寸为img_h - pad_h * 2 和 img_w - pad_w *2，因为图像两边都需要减去pad_h的尺寸。 同时我们还要给过滤器做一个上下左右变换。因为卷积操作和相关操作的过滤核移动方向是相反的，应该是从下往上，从右往左。 ","date":"2019-09-27","objectID":"/posts/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/:4:0","tags":["Python"],"title":"用python写一个过滤器","uri":"/posts/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"categories":["计算机"],"content":"实例代码： def my_imfilter(image, filter): \"\"\" Apply a filter to an image. Return the filtered image. Args - image: numpy nd-array of dim (m, n, c) - filter: numpy nd-array of dim (k, k) Returns - filtered_image: numpy nd-array of dim (m, n, c) HINTS: - You may not use any libraries that do the work for you. Using numpy to work with matrices is fine and encouraged. Using opencv or similar to do the filtering for you is not allowed. - I encourage you to try implementing this naively first, just be aware that it may take an absurdly long time to run. You will need to get a function that takes a reasonable amount of time to run so that the TAs can verify your code works. - Remember these are RGB images, accounting for the final image dimension. \"\"\" assert filter.shape[0] % 2 == 1 assert filter.shape[1] % 2 == 1 # 默认设置图像的通道数，如果只有一个通道，即输入图片是二维的。 channel = 1 # 如果输入维度=3，通道数等于第三个维度的元素数量 if image.ndim == 3: channel = image.shape[2] # 获取图片的长度和宽度 image_h, image_w = image.shape[:2] # 将过滤核做上下、左右翻转，以确保是卷积操作而不是相关操作 filter = np.flipud(filter) filter = np.fliplr(filter) # 获取过滤核的长度和宽度 filter_h, filter_w = filter.shape pad_h = (filter_h - 1) // 2 pad_w = (filter_w - 1) // 2 # 先扩充原图像,为了不影响原图像，需要复制一份图像 image_cp = image.copy() image_cp = np.pad(image_cp,[(pad_h,pad_h),(pad_w,pad_w),(0,0)],\"constant\") # 生成过滤后的图片的空容器，尺寸可以是原本的尺寸，在这里为了下面坐标转换方便，扩大了长宽。 filtered_image = np.zeros(image_cp.shape) # 第一层是对于不同的channel做卷积 for i in range(channel): # 第二层是高度y轴像素遍历 for j in range(pad_h,image_h+pad_h): # 第三层是宽度x轴像素遍历 for k in range(pad_w,image_w+pad_w): # 算法核心，加上上面的翻转式卷积操作，单独来看是相关操作。其实可以通过 step=-1来做 filtered_image[j,k,i] = np.sum(np.multiply(image_cp[j-pad_h:j+pad_h+1,k-pad_w:k+pad_w+1,i],filter)) return filtered_image[pad_h:image_h+pad_h, pad_w:image_w+pad_w,:] 相关链接： 卷积与互相关的一点探讨 ","date":"2019-09-27","objectID":"/posts/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/:5:0","tags":["Python"],"title":"用python写一个过滤器","uri":"/posts/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"categories":["个人"],"content":"在这个时刻，为了研招网确认报名而未睡，想想写写自己为什么从一个就业党到保研的路。 我从很久以前就“认清事实”，自己的学习能力只能算是中游偏下，自律和耐力也不行。 本来想着自己这不高的GPA是没有可能继续读书的，别说保研了，连考研，出国等等继续读书的可能都一一被自己否决了。还好，有编程的能力，对代码还算喜欢。本来在华为实习，基本拿到了offer。跟父母也说了自己去就业有什么不好的，拿着一份很有吸引力的薪水，做着自己也算是喜欢的编写代码的工作。 对我而言考研是不可能的。因为我害怕考研的失败和浪费自己生命的一年时间。 后来在本科导师的建议下试着投递保研申请，没想到过程是意外的轻松，也许是因为南科大的计算机系2/5左右的人都有申请出国或者就业的打算吧。 所以第一个条件满足了。但是我心里是犹豫的，因为华为的offer最终还没下来，想着一边是马上就能赚钱，购置自己喜欢的商品，另外一边是3年的研究生生活，只有奖学金的收入。 我这个人对钱很在乎的。 但是我其实是对现在进入工作抱有疑虑的，我觉得如果马上进入工作，可能很快我的生活会失衡，因为我自己的生活单调，如果再在安静的园区里工作，没有人脉，没有社交活动。生活会很枯燥的。在实习中工作的状态不是我想要的。起码工作以外很少有与人沟通交流的机会。 最终走上了读研究生这条道路，只是我应该警觉研究生3年不是一个避风港，而是自己意识到不足而该改进的一个宝贵的成长的，准备将来进入社会的一个阶段。 ","date":"2019-09-26","objectID":"/posts/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E5%86%B3%E5%AE%9A%E8%AF%BB%E7%A0%94%E7%A9%B6%E7%94%9F/:0:0","tags":["个人"],"title":"我为什么决定读研究生","uri":"/posts/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E5%86%B3%E5%AE%9A%E8%AF%BB%E7%A0%94%E7%A9%B6%E7%94%9F/"},{"categories":["计算机"],"content":"用阿里云服务器自己搭建2do同步caldav服务器 一个月前，把任务管理从Microsoft TO-DO迁移到2Do中，自己手上常用一台小米9和Macbook Pro，同步成了问题，不能使用icloud remainder。那就只有DropBox等服务可用。 因为Dropbox在国内不稳定的连接以及近阶段自己手上的梯子挂掉了，所以琢磨自己搭一个同步使用的服务器。 流程非常简单。一个小时以内就可办完。 使用到的: 阿里云ECS低配版，如果使用学生版一个月9.5元。 python3。 radicale，使用python3编写的caldav服务器程序。 ","date":"2019-09-23","objectID":"/posts/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/:1:0","tags":["Linux","Python"],"title":"用阿里云服务器自己搭建2do同步caldav服务器","uri":"/posts/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["计算机"],"content":"步骤一览: 云服务器购买与登录 安全组设置 Python3环境 安装radicale 配置radicale ","date":"2019-09-23","objectID":"/posts/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/:1:1","tags":["Linux","Python"],"title":"用阿里云服务器自己搭建2do同步caldav服务器","uri":"/posts/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["计算机"],"content":"云服务器准备 购买与登录的流程就自己搜索吧。我购买的是Ubunt的主机，也可以使用CentOS。 需要注意的是在创建服务器实例之前，最好先将本机的ssh public key导入到阿里云中，并且新建实例后选择该public key，不然不能够在终端中登录，而阿里云提供的浏览器vnc完全不能用。也可以在创建实例后再创建public key，只是需要重启实例罢了。 ","date":"2019-09-23","objectID":"/posts/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/:1:2","tags":["Linux","Python"],"title":"用阿里云服务器自己搭建2do同步caldav服务器","uri":"/posts/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["计算机"],"content":"安全组设置 阿里云默认关闭大多数端口，包括了我们这次要使用到的5232端口。所以请自行搜索“阿里云 安全组 端口开启“完成该步骤。 ","date":"2019-09-23","objectID":"/posts/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/:1:3","tags":["Linux","Python"],"title":"用阿里云服务器自己搭建2do同步caldav服务器","uri":"/posts/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["计算机"],"content":"Python3的环境搭建 这一步大体上也是请搜索“Ubuntu python3“ 需要注意的是先使用sudo apt-get update更新本地软件目录。 ","date":"2019-09-23","objectID":"/posts/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/:1:4","tags":["Linux","Python"],"title":"用阿里云服务器自己搭建2do同步caldav服务器","uri":"/posts/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["计算机"],"content":"安装radicale 这一步会很详细的讲。 安装radicale python3 -m pip install --upgrade radicale 若是在本地使用，可以使用下面这个命令。 python3 -m radicale --config \"\" --storage-filesystem-folder=~/.var/lib/radicale/collections 然后访问 http://localhost:5232 但是若在服务器上访问就无法访问。需要配置参数。 我使用的配置有，把配置文件放在/etc/radicale/config [server] # Bind all addresses hosts = 0.0.0.0:5232 daemon = True [auth] type = htpasswd htpasswd_filename = /etc/radicale/users htpasswd_encryption = plain [storage] filesystem_folder = ~/.var/lib/radicale/collections 想详细了解更多配置选项可以查看configuration 然后可以设置用户名和密码, 把配置文件放在/etc/radicale/users user:password 然后启动就好了。 python3 -m radicale 正常访问。 然后在2Do的配置上选择就好了。 ","date":"2019-09-23","objectID":"/posts/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/:1:5","tags":["Linux","Python"],"title":"用阿里云服务器自己搭建2do同步caldav服务器","uri":"/posts/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["计算机"],"content":"如何测试标准输出中的内容 标准输出：System.out.println() 方法流程： 使用OutputStream, System.setOut重定向输出流 使用System.getProperty(\"line.separator)来正确的测试下一行 使用System.setOut, System.out恢复输出流 ","date":"2019-09-23","objectID":"/posts/%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%95%E9%82%A3%E4%BA%9B%E9%9A%BE%E4%BB%A5%E6%B5%8B%E8%AF%95%E7%9A%84%E6%96%B9%E6%B3%95stdin/stdout%E6%A0%87%E5%87%86%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6main%E6%96%B9%E6%B3%95private%E7%A7%81%E6%9C%89%E6%96%B9%E6%B3%95/:1:0","tags":["软件测试","Java"],"title":"如何测试那些难以测试的方法？(stdin/stdout标准输入输出，文件，main方法，private私有方法)","uri":"/posts/%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%95%E9%82%A3%E4%BA%9B%E9%9A%BE%E4%BB%A5%E6%B5%8B%E8%AF%95%E7%9A%84%E6%96%B9%E6%B3%95stdin/stdout%E6%A0%87%E5%87%86%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6main%E6%96%B9%E6%B3%95private%E7%A7%81%E6%9C%89%E6%96%B9%E6%B3%95/"},{"categories":["计算机"],"content":"样例代码 // PrintClass.java public class PrintClass { public void printSome() { System.out.println(\"Just follow your heard\"); } } // PrintClassTest.java,忽略掉import的部分 public class PrintClassTest { @Test public void testPrintSome() { // 重定向标准输出到指定printstream中 OutputStream os = new ByteArrayOutputStream(); PrintStream ps = new PrintStream(os); System.setOut(ps); // 执行测试代码 PrintClass pc = new PrintClass(); pc.printSome(); assertEquals(\"Just follow your heard\" + System.getProperty(\"line.separator\"), os.toString()); // 恢复重定向 PrintStream originalOut = System.out; System.setOut(originalOut); } } 完整代码在：week2:printtest ","date":"2019-09-23","objectID":"/posts/%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%95%E9%82%A3%E4%BA%9B%E9%9A%BE%E4%BB%A5%E6%B5%8B%E8%AF%95%E7%9A%84%E6%96%B9%E6%B3%95stdin/stdout%E6%A0%87%E5%87%86%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6main%E6%96%B9%E6%B3%95private%E7%A7%81%E6%9C%89%E6%96%B9%E6%B3%95/:1:1","tags":["软件测试","Java"],"title":"如何测试那些难以测试的方法？(stdin/stdout标准输入输出，文件，main方法，private私有方法)","uri":"/posts/%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%95%E9%82%A3%E4%BA%9B%E9%9A%BE%E4%BB%A5%E6%B5%8B%E8%AF%95%E7%9A%84%E6%96%B9%E6%B3%95stdin/stdout%E6%A0%87%E5%87%86%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6main%E6%96%B9%E6%B3%95private%E7%A7%81%E6%9C%89%E6%96%B9%E6%B3%95/"},{"categories":["计算机"],"content":"如何测试私有方法 Java中的私有方法不能通过obj.method()的方式来调用。如果需要测试私有方法怎么办？ 使用反射机制获取这个私有方法。 需要使用到的方法Class.getDeclaredMethod(), Method.setAccessible(), Method.invoke() 方法流程： 获取需要测试类的class对象（可以使用class.forname的方法，也可以直接使用[ClassName].class的方法） 获取该class对象指定的私有方法的Method对象（[classobj.class].getDeclaredMethod(String name, Class\u003c?\u003e... parameterTypes)） 修改私有方法的访问性为公开访问([MethodObj].setAccessible(true)。 实例化需要测试类的object对象([ClassName.class].newInstance()) 调用该私有方法测试([MethodObj].invoke([objectInstance], ...)) ","date":"2019-09-23","objectID":"/posts/%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%95%E9%82%A3%E4%BA%9B%E9%9A%BE%E4%BB%A5%E6%B5%8B%E8%AF%95%E7%9A%84%E6%96%B9%E6%B3%95stdin/stdout%E6%A0%87%E5%87%86%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6main%E6%96%B9%E6%B3%95private%E7%A7%81%E6%9C%89%E6%96%B9%E6%B3%95/:2:0","tags":["软件测试","Java"],"title":"如何测试那些难以测试的方法？(stdin/stdout标准输入输出，文件，main方法，private私有方法)","uri":"/posts/%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%95%E9%82%A3%E4%BA%9B%E9%9A%BE%E4%BB%A5%E6%B5%8B%E8%AF%95%E7%9A%84%E6%96%B9%E6%B3%95stdin/stdout%E6%A0%87%E5%87%86%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6main%E6%96%B9%E6%B3%95private%E7%A7%81%E6%9C%89%E6%96%B9%E6%B3%95/"},{"categories":["计算机"],"content":"样例代码 // PrivateMethodClass.java public class PrivateMethodClass { private int privatePlus(int a, int b) { return a + b; } } // PrivateMethodClassTest.java public class PrivateMethodClassTest { @Test public void testPrivatePlus1() throws NoSuchMethodException, ClassNotFoundException, IllegalAccessException, InstantiationException, InvocationTargetException { Class cls = Class.forName(\"PrivateMethodClass\"); Method msd = cls.getDeclaredMethod(\"privatePlus\", int.class, int.class); msd.setAccessible(true); Object obj = cls.newInstance(); int res = (Integer)msd.invoke(obj, 4,6); assertEquals(10, res); } } 完整代码在：week2:privateTest ","date":"2019-09-23","objectID":"/posts/%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%95%E9%82%A3%E4%BA%9B%E9%9A%BE%E4%BB%A5%E6%B5%8B%E8%AF%95%E7%9A%84%E6%96%B9%E6%B3%95stdin/stdout%E6%A0%87%E5%87%86%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6main%E6%96%B9%E6%B3%95private%E7%A7%81%E6%9C%89%E6%96%B9%E6%B3%95/:2:1","tags":["软件测试","Java"],"title":"如何测试那些难以测试的方法？(stdin/stdout标准输入输出，文件，main方法，private私有方法)","uri":"/posts/%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%95%E9%82%A3%E4%BA%9B%E9%9A%BE%E4%BB%A5%E6%B5%8B%E8%AF%95%E7%9A%84%E6%96%B9%E6%B3%95stdin/stdout%E6%A0%87%E5%87%86%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6main%E6%96%B9%E6%B3%95private%E7%A7%81%E6%9C%89%E6%96%B9%E6%B3%95/"},{"categories":null,"content":"此系列博文是学习Coursera上Stanford的《Machine Learning》MOOC的笔记。 课程共分为11周，大约需要56小时学习。 此文是第一周的笔记。 ","date":"2019-09-13","objectID":"/posts/machine-learning-week1-note/:0:0","tags":["Machine Learning","Coursera"],"title":"Machine Learning Week1 Note","uri":"/posts/machine-learning-week1-note/"},{"categories":null,"content":"学习动机 本课程是在同学的推荐下学习的，因为大四的两个项目都需要用到机器学习的知识和工具，所以需要先对机器学习有一个大概的了解。这门课程是很有名的。且Coursera上的评分为4.9，有250多万人注册过这门课！ Ng的课程说明中对本门课程的定义为不仅 ","date":"2019-09-13","objectID":"/posts/machine-learning-week1-note/:1:0","tags":["Machine Learning","Coursera"],"title":"Machine Learning Week1 Note","uri":"/posts/machine-learning-week1-note/"},{"categories":null,"content":"介绍 机器学习的应用有： 垃圾邮件拦截。 网页搜索。 电子相册的面孔识别 机器学习适用的场景：代码不能手动编写出来。比如： 直升机自动驾驶 自然语言识别 视觉识别 机器学习在数据挖掘中的应用。 推荐系统，点击流。 ","date":"2019-09-13","objectID":"/posts/machine-learning-week1-note/:2:0","tags":["Machine Learning","Coursera"],"title":"Machine Learning Week1 Note","uri":"/posts/machine-learning-week1-note/"},{"categories":null,"content":"什么是机器学习？ 公认的机器学习的定义有两种说法。一种是Mitchell提出的ETP定义，一种是 Arthur Samuel提出的学科定义。 ","date":"2019-09-13","objectID":"/posts/machine-learning-week1-note/:3:0","tags":["Machine Learning","Coursera"],"title":"Machine Learning Week1 Note","uri":"/posts/machine-learning-week1-note/"},{"categories":null,"content":"ETP（Experience, Task, Performance） A computer is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E. Experience，实验经历。 Task：任务。 Performance：预测的准确度。 ","date":"2019-09-13","objectID":"/posts/machine-learning-week1-note/:3:1","tags":["Machine Learning","Coursera"],"title":"Machine Learning Week1 Note","uri":"/posts/machine-learning-week1-note/"},{"categories":null,"content":"Samuel的学科定义 Machine Learning is the field of study gives computers that ability to learn without being explicitly programmed. 机器学习是研究赋予不用显性的编写代码就能使计算机获得学习的能力的学科。 ","date":"2019-09-13","objectID":"/posts/machine-learning-week1-note/:3:2","tags":["Machine Learning","Coursera"],"title":"Machine Learning Week1 Note","uri":"/posts/machine-learning-week1-note/"},{"categories":null,"content":"监督学习 监督学习是指输入训练特征数据，并且告诉你正确的答案是什么，然后再输入未知的特征，通过对之前的数据挖掘出规律预测未知输入对应的输出。 监督学习需要使用标记好的特征数据训练。 监督学习可分为两种形式。一种是分类（Classification），分类的结果是离散有限的。另外一种是回归（regression），回归的输出结果是连续的。以卖房为例，分类的结果可以是预测指定房子在未来三个月是否能卖出去。而回归的结果可以是符合指定条件（比如面积和地段）的房子的预期价格。价格既可以是10000，也可以是10001.23。 在上面的例子中，面积和地段是学习模型的两个特征，除了它们以外，可能的特征还有小区绿化率、1公里内的地铁站的数量等等特征。如果需要，甚至可以使用近乎无穷数量的特征进行监督学习。 ","date":"2019-09-13","objectID":"/posts/machine-learning-week1-note/:4:0","tags":["Machine Learning","Coursera"],"title":"Machine Learning Week1 Note","uri":"/posts/machine-learning-week1-note/"},{"categories":null,"content":"非监督学习 非监督学习不需要知道输入数据的标签和分类，而是通过输入数据的结构聚类（Clustering）。比如google新闻推荐，自动以一个新闻事件为主题，聚集相关的新闻报道。或者社交网络中人群分类都可以使用非监督学习进行。 课程中举了一个Cokcktail Party Problem的问题。即通过两个不同位置的声源分离出环境音和人声。 TODO：实现一个算法 ","date":"2019-09-13","objectID":"/posts/machine-learning-week1-note/:5:0","tags":["Machine Learning","Coursera"],"title":"Machine Learning Week1 Note","uri":"/posts/machine-learning-week1-note/"},{"categories":null,"content":"2019年4月的时候用hexo和github page创建过一个博客，但是在更换电脑的时候意外丢失了模版。后又恢复回来，只剩下了网页，，没有网站配置和md原始文件。 ","date":"2019-09-08","objectID":"/posts/%E9%87%8D%E5%BB%BA%E5%8D%9A%E5%AE%A2/:0:0","tags":null,"title":"重建博客","uri":"/posts/%E9%87%8D%E5%BB%BA%E5%8D%9A%E5%AE%A2/"}]